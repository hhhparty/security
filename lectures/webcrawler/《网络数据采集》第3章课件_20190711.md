
# ç½‘ç»œçˆ¬è™«ä¸æ•°æ®é‡‡é›†è¯¾ç¨‹

# ç¬¬3ç«  Webé¡µé¢çˆ¬å–

## è¯¾å‰å¼•å¯¼

æœ¬èŠ‚è¯¾æˆ‘ä»¬å°†ä»‹ç»ä½¿ç”¨pythonå¼€å‘ç½‘ç»œçˆ¬è™«çš„åŸºæœ¬æ–¹æ³•ï¼Œå°è¯•è·å–webé¡µé¢ä¿¡æ¯ã€‚

## ä¸ŠèŠ‚å›é¡¾

ä¸ŠèŠ‚è¯¾ä»‹ç»äº†ï¼š
- ç½‘ç»œçˆ¬å–çš„å…¥å£
- ç½‘é¡µä¸‹è½½çš„åŸç†
- å†…å®¹è§£æçš„å¯¹è±¡
- å­˜å‚¨æ•°æ®çš„ä»“åº“


## æœ¬èŠ‚è¯¾ç¨‹ä¸»è¦å†…å®¹

å†…å®¹åˆ—è¡¨ï¼š

- æœ¬èŠ‚ç›®æ ‡
- çˆ¬å–Webé¡µé¢çš„åŸºæœ¬è¿‡ç¨‹ï¼›
- ä½¿ç”¨Urllibå®ç°åŸºæœ¬Webé¡µé¢çˆ¬å–ï¼›
- ä½¿ç”¨Requestsä¼˜åŒ–é¡µé¢çˆ¬å–è¿‡ç¨‹ï¼›
- æœ¬èŠ‚æ€»ç»“
- è¯¾åç»ƒä¹ 

### 1 æœ¬èŠ‚ç›®æ ‡

æœ¬èŠ‚è¯¾çš„ä¸»è¦ç›®æ ‡ï¼š

- ä½¿å­¦ç”Ÿç†è§£webé¡µé¢çˆ¬å–çš„åŸºæœ¬è¿‡ç¨‹
- ä½¿å­¦ç”Ÿèƒ½å¤Ÿè¿ç”¨python urllibåº“è®¾è®¡è‡ªå·±çš„ç®€å•webé¡µé¢çˆ¬å–ç¨‹åºï¼›
- ä½¿å­¦ç”Ÿèƒ½å¤Ÿåº”ç”¨requestsåº“ï¼Œè®¾è®¡å¯ç”¨æ€§è‰¯å¥½çš„webé¡µé¢çˆ¬å–ç¨‹åºã€‚

é‡ç‚¹ï¼š

- ç†è§£webé¡µé¢çˆ¬å–çš„åŸºæœ¬è¿‡ç¨‹
- æŒæ¡urllibçš„åŸºæœ¬ç”¨æ³•ï¼Œæ„å»ºç®€å•çˆ¬è™«ç¨‹åº
- æŒæ¡requestsçš„åŸºæœ¬ç”¨æ³•ï¼Œå¯¹ç®€å•çˆ¬è™«ç¨‹åºè¿›è¡Œä¼˜åŒ–

### 2 çˆ¬å–Webé¡µé¢çš„åŸºæœ¬è¿‡ç¨‹

æˆ‘ä»¬å…ˆä»‹ç»ä½¿ç”¨ç½‘ç»œçˆ¬è™«çˆ¬å–webé¡µé¢çš„åŸºæœ¬è¿‡ç¨‹ã€‚

#### çŸ¥è¯†è®²è§£

![Webé¡µé¢çˆ¬å–è¿‡ç¨‹](images/03/ç®€å•çˆ¬è™«è¿‡ç¨‹.png)

- ç¬¬ä¸€æ­¥ï¼Œéœ€è¦äººå·¥ç¡®å®šå¾…çˆ¬å–çš„ç›®æ ‡ç½‘é¡µçš„URLï¼Œå¹¶å°†è¿™ä¸ªURLæ”¾å…¥å¾…çˆ¬å–é˜Ÿåˆ—ã€‚

- ç¬¬äºŒæ­¥ï¼Œç½‘ç»œçˆ¬è™«ç¨‹åºè¦èƒ½å¤Ÿåƒæµè§ˆå™¨ä¸€æ ·ï¼Œæ ¹æ®è¾“å…¥çš„URLå‘è¿œç¨‹æœåŠ¡å™¨å‘å‡ºHTTPè¯·æ±‚ï¼Œå°è¯•è·å¾—å“åº”å†…å®¹ï¼Œé€šå¸¸æ˜¯ç›®æ ‡æ•°æ®æ‰€åœ¨çš„HTMLæ–‡æ¡£ã€‚

- ç¬¬ä¸‰æ­¥ï¼Œç½‘ç»œçˆ¬è™«ç¨‹åºè¦èƒ½å¤Ÿè§£æå·²ä¸‹è½½HTMLæ–‡æ¡£å†…å®¹ã€‚è¿™é‡Œçš„è§£ææŒ‡çš„æ˜¯æ£€ç´¢HTMLæ–‡æ¡£ï¼Œæå–å‡ºç›®æ ‡æ•°æ®çš„è¿‡ç¨‹ã€‚é™¤äº†ç›®æ ‡æ•°æ®ï¼Œå¯èƒ½è¿˜éœ€è¦è·å¾—æ–°çš„URLï¼Œä¸ºåç»­çˆ¬å–æä¾›ç§å­ã€‚

- ç¬¬å››æ­¥ï¼Œç½‘ç»œçˆ¬è™«ç¨‹åºéœ€è¦å°†æå–å‡ºçš„æ•°æ®ï¼ŒæŒ‰ç…§ç”¨æˆ·æ‰€éœ€çš„æ ¼å¼å­˜å‚¨ä¸‹æ¥ï¼Œé€šå¸¸ä¼šä½¿ç”¨æŸç§æ ¼å¼çš„æ–‡ä»¶æˆ–æ•°æ®åº“æ¥å­˜å‚¨æ•°æ®ï¼Œå°†éœ€è¦çš„å›¾ç‰‡æˆ–è§†é¢‘èµ„æºä¸‹è½½åˆ°ç‰¹å®šçš„æ–‡ä»¶å¤¹ä¸­ï¼Œè€Œçˆ¬å¾—çš„æ–°URLå°†æ”¾å…¥å¾…çˆ¬å–é˜Ÿåˆ—ä¸­ï¼›

- ç¬¬äº”æ­¥ï¼Œç½‘ç»œçˆ¬è™«ç¨‹åºå°†æŒ‰ä¸Šè¿°æ­¥éª¤ï¼Œé€ä¸€å¤„ç†å¾…çˆ¬å–é˜Ÿåˆ—ä¸­çš„URLï¼Œç›´åˆ°é˜Ÿåˆ—ä¸ºç©ºã€‚

ä»¥ä¸Šæ­¥éª¤ï¼Œå°±æ˜¯ä½¿ç”¨ç½‘ç»œçˆ¬è™«ç¨‹åºçˆ¬å–Webé¡µé¢çš„åŸºæœ¬è¿‡ç¨‹ã€‚åœ¨æ€è·¯ä¸Šï¼Œå®ƒå¹¶ä¸å¤æ‚ï¼Œé‚£ä¹ˆæˆ‘ä»¬èƒ½ä¸èƒ½å°†ä¹‹ä»˜è¯¸å®è·µå‘¢ï¼Ÿ


#### æ¡ˆä¾‹ä¸åº”ç”¨

æš‚æ— 

#### æ¨¡å—ç»ƒä¹ ä¸ç­”æ¡ˆ

è§ä¹ é¢˜é›†


#### å†…å®¹å°ç»“

æœ¬å°èŠ‚ä¸»è¦ä»‹ç»äº†Webé¡µé¢çˆ¬å–çš„5ä¸ªæ­¥éª¤ã€‚è¿™å‡ ç‚¹éœ€è¦å­¦ç”Ÿç‰¢è®°ã€‚

### ä½¿ç”¨Urllibå®ç°åŸºæœ¬Webé¡µé¢çˆ¬å–


#### çŸ¥è¯†è®²è§£

å·¥æ¬²åˆ©å…¶äº‹ï¼Œå¿…å…ˆåˆ©å…¶å™¨ã€‚æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæ­å»ºå¼€å‘ç½‘ç»œçˆ¬è™«ç¨‹åºçš„ç¼–ç¨‹ç¯å¢ƒã€‚

æˆ‘ä»¬å»ºè®®å¤§å®¶é€‰ç”¨Anacondaé›†æˆå¼€å‘å·¥å…·ã€‚

<img src="images/03/anaconda.jpg" width="640" alt="logo">

Anacondaæ˜¯ä¸€ä¸ªå¼€æºçš„Pythonå‘è¡Œç‰ˆæœ¬ï¼Œå…¶åŒ…å«äº†condaã€Pythonç­‰180å¤šä¸ªç§‘å­¦åŒ…åŠå…¶ä¾èµ–é¡¹ã€‚å¯¹äºå­¦ä¹ æ•°æ®ç§‘å­¦çš„åŒå­¦ï¼Œè¿™æ˜¯éå¸¸å¥½çš„ä¸€ä¸ªé›†æˆå·¥å…·ã€‚å¯¹äºå¼€å‘ç½‘ç»œçˆ¬è™«è€Œè¨€ï¼Œæˆ‘ä»¬å°†å€ŸåŠ©å®ƒçš„äº¤äº’å¼ç¼–ç¨‹ç¯å¢ƒï¼Œä»¥åŠå¤šç§æ”¯æŒåº“ï¼Œæ¥æ„å»ºæˆ‘ä»¬çš„ç¨‹åºã€‚

Anaconda3çš„å®‰è£…è¿‡ç¨‹è¾ƒä¸ºç®€å•ï¼Œä¸‹é¢å°±ä»¥Windowsç³»ç»Ÿä¸­çš„å®‰è£…è¿‡ç¨‹ä¸ºä¾‹ï¼Œä»‹ç»ä¸€ä¸‹å®‰è£…Anacondaçš„è¿‡ç¨‹å’Œå¯åŠ¨Jupyter notebookç¼–è¾‘å™¨çš„æ–¹æ³•ã€‚

- 1.è¯·ä»Anacondaå®˜æ–¹ç½‘ç«™æˆ–æ¸…åå¤§å­¦å¼€æºè½¯ä»¶é•œåƒç«™ä¸‹è½½æ”¯æŒPython3 çš„Anacondaå®‰è£…åŒ…å¹¶å¯åŠ¨å®‰è£…è¿‡ç¨‹ã€‚Windowsä¸‹é€‚ç”¨çš„Anacondaå®‰è£…åŒ…æ˜¯ä¸€ä¸ªexeå¯æ‰§è¡Œç¨‹åºï¼ŒåŒå‡»å®ƒå¯åŠ¨å®‰è£…è¿‡ç¨‹ï¼›
- 2.åœ¨é˜…è¯»äº§å“çš„Licenseæ–‡æ¡£å¹¶ç‚¹å‡»â€œI Agreeâ€åï¼Œé€‰æ‹©ä¸ºâ€œJust Meâ€æˆ–æ˜¯â€œAll usersâ€å®‰è£…è¯¥ç¨‹åºï¼Œç„¶åé€‰æ‹©å­˜æ”¾Anacondaçš„æœ¬åœ°è·¯å¾„ï¼Œæˆ‘ä»¬å»ºè®®åˆå­¦è€…ä½¿ç”¨é»˜è®¤è·¯å¾„ã€‚å¦‚æœè¦è®¾ç½®è‡ªå®šä¹‰è·¯å¾„ï¼Œè¯·ä¸è¦ä½¿ç”¨æœ‰ç©ºæ ¼å’Œéunicodeå­—ç¬¦çš„è·¯å¾„ï¼Œå¦åˆ™ä¼šå‡ºç°é”™è¯¯ã€‚
- 3.é€‰æ‹©å°†Anacondaå¢åŠ åˆ°æœ¬åœ°PATHè·¯å¾„ï¼Œå¹¶é€‰æ‹©å°†Anacondaä½œä¸ºæ‚¨çš„é»˜è®¤pythonç¼–è¯‘å™¨ã€‚
- 4.ç‚¹å‡»â€œFinishâ€å®Œæˆå®‰è£…ï¼Œä¹‹åæ‚¨å¯ä»¥åœ¨Windowsâ€œå¯åŠ¨â€çš„ç¨‹åºåˆ—è¡¨ä¸­æŸ¥çœ‹åˆ°Anacondaçš„å¯åŠ¨å¿«æ·æ–¹å¼ï¼Œä¸ºäº†éªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸï¼Œæ‚¨å¯ä»¥ç‚¹å‡»è¿è¡Œâ€œAnaconda navigatorâ€ï¼ŒæŸ¥çœ‹æ˜¯å¦æœ‰å¼¹å‡ºä¸€ä¸ªAnaconda çš„å¯¼èˆªç•Œé¢ã€‚

ç»è¿‡ä¸Šè¿°4æ­¥ï¼ŒAnacondaå°±å®‰è£…å¥½äº†ï¼Œä½†å¦‚æœä½ åœ¨å®‰è£…ä¸­å‡ºç°äº†å¼‚å¸¸é”™è¯¯ï¼Œå¯ä»¥åœ¨äº’è”ç½‘ä¸Šæœç´¢è§£ç­”ä¿¡æ¯ã€‚

å®‰è£…å¥½Anacondaåï¼Œæˆ‘ä»¬éœ€è¦å¯åŠ¨äº¤äº’å¼çš„Pythonå¼€å‘ç¯å¢ƒã€‚æˆ‘ä»¬é€‰æ‹©ç›®å‰ååˆ†æµè¡Œçš„Jupyter notebookä½œä¸ºæˆ‘ä»¬çš„äº¤äº’å¼å¼€å‘ç¯å¢ƒã€‚

å¯åŠ¨æ–¹æ³•å¾ˆç®€å•ï¼Œåœ¨â€œAnaconda navigatorâ€ç•Œé¢ä¸­å°±æœ‰å¯åŠ¨Jupyter notebookçš„æŒ‰é’®ï¼Œç‚¹å‡»ä¹‹åå°±å¯ä»¥å¯åŠ¨äº†ã€‚æ­¤å¤–ï¼Œåœ¨Windowsçš„ç¨‹åºåˆ—è¡¨ä¸­è¿˜æœ‰å•ç‹¬çš„â€œJupyter notebookâ€å¯åŠ¨é¡¹ï¼Œç‚¹å‡»åä¹Ÿå¯å¯åŠ¨å®ƒã€‚å¯åŠ¨åçš„Jupyter notebookï¼Œé€šå¸¸ä¼šä½¿ç”¨é»˜è®¤çš„æµè§ˆå™¨æ‰“å¼€ä¸€ä¸ªé¡µé¢ï¼Œè¿™ä¸ªé¡µé¢çš„URLæ˜¯http://localhost:8888/tree,

ä¸ºäº†è®¨è®ºæ–¹ä¾¿ï¼ŒåŒå­¦ä»¬å¯ä»¥åœ¨Windowså½“å‰ç”¨æˆ·ç›®å½•ä¸­çš„â€œæˆ‘çš„æ–‡æ¡£â€ä¸­æ–°å»ºä¸€ä¸ªåä¸ºâ€œMyWebCrawlersâ€çš„æ–°æ–‡ä»¶å¤¹ï¼Œç”¨æ¥å­˜æ”¾æˆ‘ä»¬å°†è¦ç¼–å†™çš„çˆ¬è™«ç¨‹åºã€‚é€šè¿‡Jupyter notebookæ‰“å¼€é¡µé¢çš„â€œnewâ€æŒ‰é’®ä¹Ÿå¯ä»¥å®ç°è¿™ä¸€ç‚¹ã€‚

ä¸Šè¿°å‡†å¤‡å·¥ä½œå®Œæˆä¹‹åï¼Œä¸‹é¢æˆ‘ä»¬å°±å¼€å§‹æ¥ç¼–å†™è‡ªå·±çš„ç¬¬ä¸€ä¸ªç½‘ç»œçˆ¬è™«ç¨‹åºå§ï¼Ÿ

é¦–å…ˆè®©æˆ‘ä»¬åœ¨Jupyter notebookæ‰“å¼€çš„æµè§ˆå™¨é¡µé¢ä¸Šï¼Œè¿›å…¥åˆšæ‰å»ºç«‹çš„â€œMyWebCrawlersâ€æ–‡ä»¶å¤¹ï¼Œç„¶åï¼Œç‚¹å‡»å³ä¸Šæ–¹çš„â€œnewâ€æŒ‰é’®ï¼Œç”Ÿæˆä¸€ä¸ªâ€œPython3â€æ–‡æ¡£ã€‚è¿™ä¸ªæ–‡æ¡£å°†æ˜¯æˆ‘ä»¬ç¼–å†™ç¨‹åºçš„ä¸»è¦åœºæ‰€ã€‚

æˆ‘ä»¬ç¼–å†™Pythonç½‘ç»œçˆ¬è™«æ—¶ï¼Œéœ€è¦å€ŸåŠ©ä¸€äº›æ”¯æŒåº“æ¥ç®€åŒ–æˆ‘ä»¬çš„ç¼–å†™è¿‡ç¨‹ï¼Œä¾‹å¦‚ä½¿ç”¨Python3å†…ç½®çš„Urllibåº“å°±æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚Urllibåº“ä¸­åŒ…å«äº†4ä¸ªå¤„ç†URLçš„æ¨¡å—ï¼Œåˆ†åˆ«æ˜¯ï¼š

- Urllib.requestï¼Œå®ƒç”¨äºæ‰“å¼€å’Œè¯»å–URLã€‚
  - åœ¨Urllib.requestæ¨¡å—ä¸­å®šä¹‰äº†ä¸€äº›æ‰“å¼€urlçš„æ–¹æ³•å’Œç±»ï¼Œé™¤äº†å¯ä»¥å¸®åŠ©æˆ‘ä»¬è·å–webé¡µé¢ï¼Œè¿˜å¯ä»¥å¸®åŠ©æˆ‘ä»¬å¤„ç†ç®€å•æˆ–æ‘˜è¦ç±»å‹çš„é¡µé¢è®¤è¯ï¼Œé¡µé¢é‡å®šå‘ã€ä»¥åŠcookiesç­‰è®¿é—®webé¡µé¢æ—¶çš„å¸¸è§é—®é¢˜ã€‚

- urllib.error ï¼Œå®ƒåŒ…å«äº†requestæ¨¡å—å¯èƒ½å¼•å‘çš„å¼‚å¸¸ï¼›

- urllib.parse ï¼Œå®ƒç”¨äºè§£æURL

- urllib.robotparser ç”¨äºè§£æ robots.txt æ–‡ä»¶ã€‚

è¿™äº›æ¨¡å—çš„ä½¿ç”¨ç»†èŠ‚ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„è¯¾ç¨‹ä¸­ä¾æ¬¡è®²è§£ã€‚

ä¸‹é¢ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨urllibå®Œæˆä»¥ä¸‹å‡ ä¸ªä»»åŠ¡ï¼š

1.	è®¿é—®æŒ‡å®šçš„URLï¼Œè·å–å“åº”ç»“æœï¼›
2.	ä½¿è®¾ç½®HTTPè¯·æ±‚å¤´å‚æ•°ï¼Œä½¿ç½‘ç»œçˆ¬è™«æ›´åƒæµè§ˆå™¨è¡Œä¸ºï¼›
3.	ä½¿ç”¨GETæˆ–POSTæ–¹æ³•ï¼Œå‘æœåŠ¡å™¨ä¼ é€’å‚æ•°ï¼›
4.	å­¦ä¼šå¤„ç†å¸¸è§å¼‚å¸¸

è¦æƒ³è®¿é—®æŒ‡å®šçš„URLï¼Œé€šå¸¸ä¼šä½¿ç”¨urllib.requestä¸­çš„urlopenå‡½æ•°ã€‚

ä½¿ç”¨urllibé¦–å…ˆè¦å¼•å…¥urllibåº“ã€‚

```python
import urllib

help(urllib)


    Help on package urllib:
    
    NAME
        urllib
    
    PACKAGE CONTENTS
        error
        parse
        request
        response
        robotparser
    
    FILE
        d:\pythonspace\anaconda3\lib\urllib\__init__.py
   
```   
        

åœ¨æˆ‘ä»¬äº†è§£äº†urllibä¸­çš„åŒ…é€‰é¡¹ï¼ˆå³å­æ¨¡å—ï¼‰åï¼Œå°±ä½¿ç”¨æ›´ä¸ºç²¾ç¡®çš„å¼•å…¥æ–¹å¼ã€‚


```python
import urllib.error
import urllib.parse
import urllib.request
import urllib.robotparser
import urllib.response
```

è¿™å…¶ä¸­æˆ‘ä»¬å°†é¢‘ç¹ä½¿ç”¨çš„requeståŒ…ï¼Œä½¿ç”¨helpæ–¹æ³•ï¼Œå¯ä»¥æŸ¥çœ‹å…¶åŸºæœ¬ä¿¡æ¯ã€‚

å¯ä»¥ä»ä¸­çœ‹å‡ºï¼Œurllib.requestçš„ä¸»è¦åŠŸèƒ½æ˜¯ä½¿ç”¨å„ç§ç½‘ç»œåè®®ï¼ˆä¾‹å¦‚httpï¼‰æ‰“å¼€urlã€‚å®ƒä¹Ÿæ˜¯ä½¿ç”¨urlopenè·å–æŸä¸ªç½‘é¡µæœ€ç®€å•çš„æ–¹å¼ã€‚

åœ¨å¸®åŠ©ä¸­ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªä¾‹å­ã€‚ä½†è¿™ä¸ªä¾‹å­ä¼˜ç‚¹å¤æ‚ï¼Œæˆ‘ä»¬ç¨åå†è¿›è¡Œä»‹ç»ã€‚


```python
help(urllib.request)

# ä»¥ä¸‹ä¸ºç»“æœ
    Help on module urllib.request in urllib:
    
    NAME
        urllib.request - An extensible library for opening URLs using a variety of protocols
    
    DESCRIPTION
        The simplest way to use this module is to call the urlopen function,
        which accepts a string containing a URL or a Request object (described
        below).  It opens the URL and returns the results as file-like
        object; the returned object has some extra methods described below.
        
        ...
        
        urlopen(url, data=None) -- Basic usage is the same as original
        urllib.  pass the url and optionally data to post to an HTTP URL, and
        get a file-like object back.  One difference is that you can also pass
        a Request instance instead of URL.  Raises a URLError (subclass of
        OSError); for HTTP errors, raises an HTTPError, which can also be
        treated as a valid response.
        ...
        
        Request -- An object that encapsulates the state of a request.  The
        state can be as simple as the URL.  It can also include extra HTTP
        headers, e.g. a User-Agent.
        
        ...

        Example usage:
        
        import urllib.request
        
        # set up authentication info
        authinfo = urllib.request.HTTPBasicAuthHandler()
        authinfo.add_password(realm='PDQ Application',
                              uri='https://mahler:8092/site-updates.py',
                              user='klem',
                              passwd='geheim$parole')
        
        proxy_support = urllib.request.ProxyHandler({"http" : "http://ahad-haam:3128"})
        
        # build a new opener that adds authentication and caching FTP handlers
        opener = urllib.request.build_opener(proxy_support, authinfo,
                                             urllib.request.CacheFTPHandler)
        
        # install it
        urllib.request.install_opener(opener)
        
        f = urllib.request.urlopen('http://www.python.org/')
    
    ...
       
    
    VERSION
        3.7
    
    FILE
        d:\pythonspace\anaconda3\lib\urllib\request.py
    
```   
    

**1 ä½¿ç”¨urllib.request.urlopen æ–¹æ³•è®¿é—®æŒ‡å®šçš„URL**

ä¸ºäº†ä½¿åˆå­¦è€…ä¸è‡³äºè¢«è¿‡å¤šçš„ç»†èŠ‚æ‰€å›°æ‰°ï¼Œæˆ‘ä»¬ä¸‹é¢å…ˆä»‹ç»ä½¿ç”¨urllib.requestä¸­æœ€å¸¸ç”¨çš„urlopenæ–¹æ³•ã€‚

urlopenå®ƒä¹Ÿæ˜¯æˆ‘ä»¬ä½¿ç”¨urllibè·å–æ™®é€šç½‘é¡µçš„åŸºæœ¬æ–¹æ³•ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ helpæ–¹æ³•ï¼Œè·å–è¿™ä¸ªå‡½æ•°çš„åŸå‹


```python
help(urllib.request.urlopen)

# ä»¥ä¸‹ä¸ºç»“æœ
    Help on function urlopen in module urllib.request:
    
    urlopen(url, data=None, timeout=<object object at 0x000002C994D8E6A0>, *, cafile=None, capath=None, cadefault=False, context=None)
        Open the URL url, which can be either a string or a Request object.
        
        *data* must be an object specifying additional data to be sent to
        the server, or None if no such data is needed.  See Request for
        details.
        
        urllib.request module uses HTTP/1.1 and includes a "Connection:close"
        header in its HTTP requests.
        
        The optional *timeout* parameter specifies a timeout in seconds for
        blocking operations like the connection attempt (if not specified, the
        global default timeout setting will be used). This only works for HTTP,
        HTTPS and FTP connections.
        
        If *context* is specified, it must be a ssl.SSLContext instance describing
        the various SSL options. See HTTPSConnection for more details.
        
        The optional *cafile* and *capath* parameters specify a set of trusted CA
        certificates for HTTPS requests. cafile should point to a single file
        containing a bundle of CA certificates, whereas capath should point to a
        directory of hashed certificate files. More information can be found in
        ssl.SSLContext.load_verify_locations().
        
        The *cadefault* parameter is ignored.
        
        This function always returns an object which can work as a context
        manager and has methods such as
        
        * geturl() - return the URL of the resource retrieved, commonly used to
          determine if a redirect was followed
        
        * info() - return the meta-information of the page, such as headers, in the
          form of an email.message_from_string() instance (see Quick Reference to
          HTTP Headers)
        
        * getcode() - return the HTTP status code of the response.  Raises URLError
          on errors.
        
        For HTTP and HTTPS URLs, this function returns a http.client.HTTPResponse
        object slightly modified. In addition to the three new methods above, the
        msg attribute contains the same information as the reason attribute ---
        the reason phrase returned by the server --- instead of the response
        headers as it is specified in the documentation for HTTPResponse.
        
        For FTP, file, and data URLs and requests explicitly handled by legacy
        URLopener and FancyURLopener classes, this function returns a
        urllib.response.addinfourl object.
        
        Note that None may be returned if no handler handles the request (though
        the default installed global OpenerDirector uses UnknownHandler to ensure
        this never happens).
        
        In addition, if proxy settings are detected (for example, when a *_proxy
        environment variable like http_proxy is set), ProxyHandler is default
        installed and makes sure the requests are handled through the proxy.
    
```   

ä»ä¸Šé¢çš„å¸®åŠ©ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œè¿™ä¸ªå‡½æ•°çš„ä¸€äº›ç»†èŠ‚ï¼š

- **åŠŸèƒ½**ï¼šå‡½æ•° urlopen ç”¨äºæ‰“å¼€å‚æ•°urlæŒ‡å®šçš„é¡µé¢ï¼Œè¿™ä¸ªurlå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–æ˜¯ä¸€ä¸ªè¯·æ±‚å¯¹è±¡ã€‚

- **å‚æ•°**ï¼šå‡½æ•° urlopen æœ‰7ä¸ªå‚æ•°ã€‚
  - urlï¼šç”¨äºæŒ‡å®šå°†è¦è®¿é—®çš„ç½‘é¡µurlï¼Œæ— é»˜è®¤å€¼ï¼Œå¿…é¡»ç”±ç”¨æˆ·ç»™å‡ºã€‚
  - dataï¼šç”¨äºåŠ è½½ç”¨æˆ·ä¼ é€’ç»™æœåŠ¡å™¨çš„æ•°æ®ï¼›é»˜è®¤å€¼ä¸ºNoneï¼›
  - timeoutï¼šç”¨äºè®¾ç½®è¶…æ—¶æ—¶é—´ï¼Œæ˜¯ä¸€ä¸ªæ—¶é—´ç±»å‹çš„=<object object at 0x000001BAE831E6A0>, 
  - cafile=None, capath=None, cadefault=Falseï¼Œè¿™ä¸‰ä¸ªå‚æ•°ä¸ç”¨æˆ·è¯ä¹¦æœ‰å…³
  - context=Noneï¼Œè¿™ä¸ªå‚æ•°ç”¨äºä¼ é€’å„ç±»å‹çš„SSLå‚æ•°ã€‚

- **è¿”å›å€¼**ï¼š
  - å¯¹äºHTTPã€HTTPSç±»å‹çš„URLï¼Œå‡½æ•°è¿”å›æ˜¯http.client.HTTPResponseå¯¹è±¡ï¼›
  - å¯¹äºFTPã€æ–‡ä»¶ã€æ•°æ®URLå’Œè¯·æ±‚å¯¹è±¡å‹çš„URLï¼Œå‡½æ•°è¿”å›ä¸€ä¸ªurllib.response.addinfourlå¯¹è±¡ã€‚

ä¸‹é¢æˆ‘ä»¬å°è¯•ä½¿ç”¨urlopenï¼Œæ¥å®ç°**ç›®æ ‡1.è®¿é—®æŒ‡å®šçš„urlï¼Œè·å–å“åº”ç»“æœ**ã€‚


```python
import urllib.request

url = "http://www.baidu.com"
r = urllib.request.urlopen(url)
print(r)
```

    <http.client.HTTPResponse object at 0x000002C9975FA588>
    

ç”±äºurlopençš„è¿”å›å€¼æ˜¯http.client.HTTPResponseç±»å‹ï¼Œæ‰€ä»¥ä¸ºäº†å¾—åˆ°äººä»¬å¯è¯»çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¸‹é¢ç®€å•æ¢ç´¢ä¸€ä¸‹è¿™ä¸ªç±»å‹ã€‚

è¿˜æ˜¯ä½¿ç”¨helpæ–¹æ³•,æˆ‘ä»¬ä¸»è¦å…³æ³¨å®ƒçš„æ–¹æ³•


```python
help(r)

# ä»¥ä¸‹ä¸ºç»“æœ

    Help on HTTPResponse in module http.client object:
    
    class HTTPResponse(io.BufferedIOBase)
     |  HTTPResponse(sock, debuglevel=0, method=None, url=None)
     |  
     |  Base class for buffered IO objects.
     |  
     |  The main difference with RawIOBase is that the read() method
     |  supports omitting the size argument, and does not have a default
     |  implementation that defers to readinto().
     |  
     |  In addition, read(), readinto() and write() may raise
     |  BlockingIOError if the underlying raw stream is in non-blocking
     |  mode and not ready; unlike their raw counterparts, they will never
     |  return None.
     |  
     |  A typical implementation should not inherit from a RawIOBase
     |  implementation, but wrap one.
   
```  

http.client.HTTPResponseå¯¹è±¡å¯è°ƒç”¨çš„æ–¹æ³•ä¸­ï¼Œæœ‰å‡ ä¸ªå¾ˆé‡è¦ï¼Œä½¿ç”¨å®ƒä»¬å¯ä»¥è·å¾—æˆ‘ä»¬æ‰€éœ€çš„ä¿¡æ¯.

å®ƒä»¬åˆ†åˆ«æ˜¯ï¼š

- read()æ–¹æ³•,ç”¨äºä»¥å­—èŠ‚å½¢å¼ï¼Œè¯»å–å¹¶è¿”å›å“åº”å†…å®¹ï¼›
- geturl()æ–¹æ³•ï¼Œç”¨äºè¿”å›é¡µé¢çœŸå®çš„urlï¼›
- info()æ–¹æ³•ï¼Œç”¨äºè¿”å›ä¸URLç›¸å…³çš„å…ƒä¿¡æ¯ï¼›
- getheaders()æ–¹æ³•ï¼Œç”¨äºè¿”å›å“åº”å¤´éƒ¨ä¿¡æ¯ï¼›
- getcode()æ–¹æ³•ï¼Œç”¨äºè¿”å›httpå“åº”ä»£ç ï¼›

ä¸ºäº†å¾—åˆ°äººç±»å¯è¯»çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨çš„æ˜¯readæ–¹æ³•ã€‚æˆ‘ä»¬æŠŠä¸Šé¢çš„ä»£ç åšç®€å•ä¿®æ”¹,å°±å¯ä»¥çœ‹åˆ°å“åº”å†…å®¹äº†ã€‚


```python
import urllib.request

url = "http://www.baidu.com"
r = urllib.request.urlopen(url)
print(r.read())

# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    b'<!DOCTYPE html>\n<!--STATUS OK-->\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\t\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\t\r\n        \r\n\t\t\t        \r\n\t\r\n\t\t\t        \r\n\t\r\n\t\t\t        \r\n\t\r\n\t\t\t        \r\n\t\t\t    \r\n\r\n\t\r\n        \r\n\t\t\t        \r\n\t\r\n\t\t\t        \r\n\t\r\n\t\t\t        \r\n\t\r\n\t\t\t        \r\n\t\t\t    \r\n\r\n\r\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<head>\n    \n    <meta http-equiv="content-type" content="text/html;charset=utf-8">\n    <meta http-equiv="X-UA-Compatible" content="IE=Edge">\n\t<meta content="always" name="referrer">\n    <meta name="theme-color" content="#2932e1">\n    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />\n    <link rel="search" type="application/opensearchdescription+xml" href="/content-search.xml" title="\xe7\x99\xbe\xe5\xba\xa6\xe6\x90\x9c\xe7\xb4\xa2" />\n    <link rel="icon" sizes="any" mask href="//www.baidu.com/img/baidu_85beaf5496f291521eb75ba38eacbd87.svg">\n\t\n\t\n\t<link rel="dns-prefetch" href="//s1.bdstatic.com"/>\n\t<link rel="dns-prefetch" href="//t1.baidu.com"/>\n\t<link rel="dns-prefetch" href="//t2.baidu.com"/>\n\t<link rel="dns-prefetch" href="//t3.baidu.com"/>\n\t<link rel="dns-prefetch" href="//t10.baidu.com"/>\n\t<link rel="dns-prefetch" href="//t11.baidu.com"/>\n\t<link rel="dns-prefetch" href="//t12.baidu.com"/>\n\t<link rel="dns-prefetch" href="//b1.bdstatic.com"/>\n    \n    <title>\xe7\x99\xbe\xe5\xba\xa6\xe4\xb8\x80\xe4\xb8\x8b\xef\xbc\x8c\xe4\xbd\xa0\xe5\xb0\xb1\xe7\x9f\xa5\xe9\x81\x93</title>\n    \n\n<style id="css_index" index="index" type="text/css">html,body{height:100%}
    ......
    'result_kw\':"#kw"\n});\n</script>\n\n<script>\nif(navigator.cookieEnabled){\n\tdocument.cookie="NOJS=;expires=Sat, 01 Jan 2000 00:00:00 GMT";\n}\n</script>\n\n\n\n</body>\n</html>\n\n\r\n\n\n\r\n'
```

äº‹å®ä¸Šï¼Œä¸Šé¢çš„r ï¼Œå³http.client.HTTPResponseå¯¹è±¡ï¼Œä¼šä»¥æ–‡ä»¶å½¢å¼ä¿å­˜åœ¨ç¼“å­˜ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨readæ–¹æ³•å°†å®ƒè¯»å‡ºã€‚

ç”±äºè¯»å–æ–¹æ³•å±äºioæ“ä½œï¼Œä¸ºäº†ç¡®ä¿åœ¨è¯»å–IOèµ„æºåæ­£ç¡®å…³é—­èµ„æºï¼Œæ‰€ä»¥æˆ‘ä»¬æ¨èä½¿ç”¨ä¸‹åˆ—æ–¹æ³•ã€‚å³ä½¿ç”¨withè¯­å¥ï¼Œwithè¯­å¥æ˜¯pythonä¸­å¤„ç†IOèµ„æºçš„ç»å…¸è¯­å¥ï¼Œå®ƒå¯ä»¥ç¡®ä¿æ‰“å¼€çš„èµ„æºåœ¨æ‰§è¡Œå®Œwithè¯­å¥ä¹‹åæ­£ç¡®çš„è¢«å…³é—­ï¼Œè€Œä¸ä¼šå› ç¨‹åºå‘˜é—å¿˜è€Œå½¢æˆéšæ‚£ã€‚

å¯ä»¥çœ‹åˆ°ï¼Œå“åº”å†…å®¹ç”±å¾ˆå¤šçš„å­—ç¬¦ç»„æˆï¼Œè¿™äº›å­—ç¬¦äº‹å®ä¸Šå°±æ˜¯æˆ‘ä»¬ä½¿ç”¨æµè§ˆå™¨è®¿é—®www.baidu.com è¿™ä¸ªurlæ—¶å¾—åˆ°çš„ç½‘é¡µæºä»£ç ã€‚

ä¸ºäº†éªŒè¯è¿™ä¸€äº‹å®ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨googleæµè§ˆå™¨chromeçš„å¼€å‘è€…å·¥å…·æ¥æŸ¥çœ‹ã€‚

ç”±äºreadæ–¹æ³•è¿”å›çš„æ˜¯å­—èŠ‚å‹æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶è¿”å›å€¼è§†ä¸ºå­—ç¬¦ä¸²ï¼Œå­—ç¬¦ä¸²åœ¨pythonä¸­æ˜¯ä¸€ç§ç‰¹æ®Šçš„åˆ—è¡¨ï¼Œæ‰€ä»¥å¦‚æœåªéœ€è¦è·å¾—å“åº”ç»“æœä¸­çš„éƒ¨åˆ†å†…å®¹ï¼Œå¯ä»¥ä½¿ç”¨åˆ—è¡¨åˆ‡ç‰‡æ¥å®ç°ã€‚ä¾‹å¦‚ï¼š


```python
import urllib.request

url = "http://www.baidu.com"
with urllib.request.urlopen(url) as r:
    print(r.read()[500:1000])

# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    b'<meta http-equiv="X-UA-Compatible" content="IE=Edge">\n\t<meta content="always" name="referrer">\n    <meta name="theme-color" content="#2932e1">\n    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />\n    <link rel="search" type="application/opensearchdescription+xml" href="/content-search.xml" title="\xe7\x99\xbe\xe5\xba\xa6\xe6\x90\x9c\xe7\xb4\xa2" />\n    <link rel="icon" sizes="any" mask href="//www.baidu.com/img/baidu_85beaf5496f291521eb75ba38eacbd87.svg">\n\t\n\t\n\t<link rel="dns-prefetch" href="//s1.bdstatic.com"/>'
    
```

å¯ä»¥çœ‹åˆ°ï¼Œä¸Šé¢çš„å“åº”ç»“æœä¸­å­˜åœ¨ä¸€äº›ä¸å¯è¯»ç¼–ç ï¼Œç‰¹åˆ«æ˜¯ä¸€äº›æœ‰æ„ä¹‰çš„æ ‡ç­¾å†…å®¹ï¼Œä¾‹å¦‚titleçš„å†…å®¹ã€‚

å¦‚ä½•å°†è¿™äº›ç¼–ç è½¬æ¢ä¸ºå¯è¯»ç¼–ç å‘¢ï¼Ÿ

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨decode()æ–¹æ³•ï¼Œä¾‹å¦‚ï¼š


```python
import urllib.request

url = "http://www.baidu.com"
with urllib.request.urlopen(url) as r:
    print(r.read()[500:1000].decode('utf-8'))
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    	<meta content="always" name="referrer">
        <meta name="theme-color" content="#2932e1">
        <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
        <link rel="search" type="application/opensearchdescription+xml" href="/content-search.xml" title="ç™¾åº¦æœç´¢" />
        <link rel="icon" sizes="any" mask href="//www.baidu.com/img/baidu_85beaf5496f291521eb75ba38eacbd87.svg">
    	
    	
    	<link rel="dns-prefetch" href="//s1.bdstatic.com"/>
```  

å¦‚æœä½ æƒ³æŠŠç¼“å­˜çš„æ–‡ä»¶ä¿å­˜ä¸‹æ¥ï¼Œå¯ä»¥ä½¿ç”¨urllib.request.urlretrieve()æ–¹æ³•ã€‚


```python
help(urllib.request.urlretrieve)

# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    Help on function urlretrieve in module urllib.request:
    
    urlretrieve(url, filename=None, reporthook=None, data=None)
        Retrieve a URL into a temporary location on disk.
        
        Requires a URL argument. If a filename is passed, it is used as
        the temporary file location. The reporthook argument should be
        a callable that accepts a block number, a read size, and the
        total file size of the URL target. The data argument should be
        valid URL encoded data.
        
        If a filename is passed and the URL points to a local resource,
        the result is a copy from local file to new file.
        
        Returns a tuple containing the path to the newly created
        data file as well as the resulting HTTPMessage object.
``` 
    

urllib.request.urlretrieve()æ–¹æ³•ç”¨äºè®¿é—®æŒ‡å®šurlï¼Œå¹¶å°†å“åº”å†…å®¹å­˜å‚¨åˆ°æœ¬åœ°çš„ä¸´æ—¶æ–‡ä»¶ä¸­ã€‚

ä½¿ç”¨æ—¶éœ€è¦ç‰¹åˆ«æŒ‡å®šçš„å‚æ•°æœ‰ï¼š
- urlï¼šå¾…è®¿é—®çš„é¡µé¢åœ°å€ã€‚
- filenameï¼šå­˜å‚¨å“åº”ç»“æœçš„æ–‡ä»¶è·¯å¾„ã€‚

urllib.request.urlretrieve()æ–¹æ³•çš„è¿”å›å€¼æ˜¯ä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…æ‹¬ä¸¤æ–¹é¢ï¼š

- æ–°ç”Ÿæˆçš„æ–‡ä»¶å
- å“åº”äº§ç”Ÿçš„HTTPMessageå¯¹è±¡


```python
import urllib.request

url = "http://www.baidu.com"
localfile, headers = urllib.request.urlretrieve(url)
print("å“åº”å¤´ä¿¡æ¯ï¼š")
print(headers)
print("æœ¬åœ°æ–‡ä»¶åï¼š")
print(localfile)

# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    å“åº”å¤´ä¿¡æ¯ï¼š
    Bdpagetype: 1
    Bdqid: 0xb7726796003073b2
    Cache-Control: private
    Content-Type: text/html
    Cxy_all: baidu+d6a8029e425f552015c6586a032a3206
    Date: Thu, 11 Jul 2019 07:15:07 GMT
    Expires: Thu, 11 Jul 2019 07:14:49 GMT
    P3p: CP=" OTI DSP COR IVA OUR IND COM "
    Server: BWS/1.1
    Set-Cookie: BAIDUID=006F323E4A1132EC633BD24290A34F73:FG=1; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
    Set-Cookie: BIDUPSID=006F323E4A1132EC633BD24290A34F73; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
    Set-Cookie: PSTM=1562829307; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
    Set-Cookie: delPer=0; path=/; domain=.baidu.com
    Set-Cookie: BDSVRTM=0; path=/
    Set-Cookie: BD_HOME=0; path=/
    Set-Cookie: H_PS_PSSID=1423_21093_29523_29521_29238_28518_29099_28836_29220; path=/; domain=.baidu.com
    Vary: Accept-Encoding
    X-Ua-Compatible: IE=Edge,chrome=1
    Connection: close
    Transfer-Encoding: chunked
    
    
    æœ¬åœ°æ–‡ä»¶åï¼š
    C:\Users\leo\AppData\Local\Temp\tmp__eiqy59
```   

**HTTPResponse å¯¹è±¡**

HTTPResponseå¯¹è±¡æ˜¯ä¸€ç§ç±»æ–‡ä»¶å¯¹è±¡ï¼Œé™¤äº†å¯ä»¥æ–‡ä»¶çš„read()æ–¹æ³•è¯»å–å®ƒçš„å†…å®¹å¤–ï¼Œè¿˜æœ‰åˆ«çš„å±æ€§å’Œæ–¹æ³•ã€‚ 

- r.codeä¸r.statuså±æ€§å­˜æ”¾æœ¬æ¬¡è¯·æ±‚çš„å“åº”ç ;
- r.headerså±æ€§å­˜æ”¾å“åº”å¤´ï¼›
- r.urlå±æ€§å­˜æ”¾äº†å‘å‡ºå“åº”çš„æœåŠ¡å™¨URLï¼›
- r.info()
- r.geturl()æ–¹æ³•

ä½¿ç”¨responseçš„geturl()å’Œinfoæ–¹æ³•æ¥éªŒè¯è¯·æ±‚ä¸å“åº”æ˜¯å¦å¦‚æˆ‘ä»¬å¸Œæœ›çš„ä¸€æ ·ã€‚æœ‰æ—¶ä¼šå‡ºç°è¯·æ±‚å‘å¾€çš„æœåŠ¡å™¨ä¸åº”ç­”æœåŠ¡å™¨ä¸æ˜¯åŒä¸€å°ä¸»æœºçš„æƒ…å†µã€‚


```python
"""ç†è§£HTTPResponseå¯¹è±¡
"""
import urllib.request

url = 'http://www.baidu.com'
with urllib.request.urlopen(url) as r:
    print('å“åº”ç ï¼š')
    print(r.code)
    #print(r.status)
    print('å“åº”å¤´ä¿¡æ¯ï¼š')
    #print(r.headers)
    print(r.info())
    print('è·å¾—é¡µé¢çš„çœŸå®urlï¼š')
    #print(r.url)
    print(r.geturl())


# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    å“åº”ç ï¼š
    200
    å“åº”å¤´ä¿¡æ¯ï¼š
    Bdpagetype: 1
    Bdqid: 0xdc6d87de002f9bc1
    Cache-Control: private
    Content-Type: text/html
    Cxy_all: baidu+74098a06a74a3752310420b2c161e5ce
    Date: Thu, 11 Jul 2019 07:15:48 GMT
    Expires: Thu, 11 Jul 2019 07:15:35 GMT
    P3p: CP=" OTI DSP COR IVA OUR IND COM "
    Server: BWS/1.1
    Set-Cookie: BAIDUID=386F6B1508A7F49276508F9C2C09BA9E:FG=1; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
    Set-Cookie: BIDUPSID=386F6B1508A7F49276508F9C2C09BA9E; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
    Set-Cookie: PSTM=1562829348; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
    Set-Cookie: delPer=0; path=/; domain=.baidu.com
    Set-Cookie: BDSVRTM=0; path=/
    Set-Cookie: BD_HOME=0; path=/
    Set-Cookie: H_PS_PSSID=1433_21117_29522_29519_29237_28519_29098_28836_29220_26350; path=/; domain=.baidu.com
    Vary: Accept-Encoding
    X-Ua-Compatible: IE=Edge,chrome=1
    Connection: close
    Transfer-Encoding: chunked
    
    
    è·å¾—é¡µé¢çš„çœŸå®urlï¼š
    http://www.baidu.com
```

**2 ä½¿è®¾ç½®HTTPè¯·æ±‚å¤´å‚æ•°ï¼Œä½¿ç½‘ç»œçˆ¬è™«æ›´åƒæµè§ˆå™¨è¡Œä¸º**

ä¸‹é¢ï¼Œæˆ‘ä»¬å°è¯•ä½¿ç”¨urllibå®Œæˆæœ¬è®²çš„ç¬¬2ä¸ªä»»åŠ¡ã€‚

WebæœåŠ¡å™¨åœ¨æ¥æ”¶å®¢æˆ·ç«¯è¯·æ±‚æ—¶ï¼Œæœ‰æ—¶ä¼šæ ¹æ®å®¢æˆ·ç«¯ç±»å‹ç»™å‡ºå“åº”ç»“æœï¼Œä¾‹å¦‚æ‰‹æœºæµè§ˆå™¨è®¿é—®ç™¾åº¦ä¸pcæµè§ˆå™¨è®¿é—®ç™¾åº¦çš„ç»“æœå°±ä¸ç›¸åŒã€‚

æˆ‘ä»¬åšä¸¤ä¸ªä¸ªå®éªŒæ¥éªŒè¯ï¼š

- å®éªŒ1 åˆ©ç”¨httpbinç½‘ç«™çš„user-agentå“åº”åŠŸèƒ½ï¼ŒæŸ¥çœ‹è¯·æ±‚å¤´ä¸­çš„user-agent

ä½¿ç”¨è¿™ä¸ªåŠŸèƒ½æ—¶ï¼Œéœ€è¦å…ˆç™»å½•httpbinç½‘ç«™ï¼Œè®¾ç½®user-agentåŠŸèƒ½ã€‚


```python
import urllib.request

url = "http://www.httpbin.org/user-agent"
with urllib.request.urlopen(url) as r:
    print(r.read())
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    b'{\n  "user-agent": "Python-urllib/3.7"\n}\n'
```   


```python
import urllib.request

url = "http://www.httpbin.org/user-agent"
headers = {'User-Agent':'Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5'}
request = urllib.request.Request(url,headers=headers)

with urllib.request.urlopen(request) as r:
    print(r.read())   

# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    b'{\n  "user-agent": "Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5"\n}\n'
```   

- å®éªŒ2 ä½¿ç”¨ä¸åŒçš„user-agentè®¿é—®ç™¾åº¦


```python
import urllib.request

url = "http://www.baidu.com"
with urllib.request.urlopen(url) as r:
    print(r.read()[500:2000].decode('utf-8'))

# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
 
        
        <title>ç™¾åº¦ä¸€ä¸‹ï¼Œä½ å°±çŸ¥é“</title>

```

```python
import urllib.request

url = "http://www.baidu.com"
headers = {'User-Agent':'Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5'}
request = urllib.request.Request(url,headers=headers)

with urllib.request.urlopen(request) as r:
    print(r.read()[500:2000].decode('utf-8')) 
```
```
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

<title>ç™¾åº¦ä¸€ä¸‹</title><script>window._performanceTimings=[['firstLine',+new Date
```

é€šè¿‡ä¸Šé¢çš„å®éªŒï¼Œæˆ‘ä»¬å¯ä»¥ç¡®å®šçš„æ˜¯ï¼Œå®¢æˆ·ç«¯ä½¿ç”¨ä¸åŒçš„user-agentå€¼ï¼ŒæœåŠ¡å™¨ä¼šæœ‰ä¸åŒçš„å“åº”ã€‚

æœ‰äº›ç½‘ç«™æœåŠ¡å™¨è¿˜ä¼šæ ¹æ®è¿™ä¸€ç‚¹ï¼Œé™åˆ¶ç½‘ç»œçˆ¬è™«çš„è®¿é—®ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è®¾ç½®çˆ¬è™«çš„user-agentï¼Œä½¿å…¶æ›´åƒä¸€èˆ¬çš„PCæˆ–æ‰‹æœºã€‚

ä¸‹é¢ä¸¾ä¾‹è¯´æ˜ï¼š

**å°†çˆ¬è™«ç¨‹åºä¼ªè£…ä¸ºPCç‰ˆchromeæµè§ˆå™¨**


```python
import urllib.request

url = "http://www.baidu.com"
headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
request = urllib.request.Request(url,headers=headers)

with urllib.request.urlopen(request) as r:
    print(r.read()[500:2000].decode('utf-8')) 
```
```
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    	<meta content="always" name="referrer">
        <meta name="theme-color" content="#2932e1">
        <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
        <link rel="search" type="application/opensearchdescription+xml" href="/content-search.xml" title="ç™¾åº¦æœç´¢" />
        <link rel="icon" sizes="any" mask href="//www.baidu.com/img/baidu_85beaf5496f291521eb75ba38eacbd87.svg">
    	
    	
    	<link rel="dns-prefetch" href="//s1.bdstatic.com"/>
    	<link rel="dns-prefetch" href="//t1.baidu.com"/>
    	<link rel="dns-prefetch" href="//t2.baidu.com"/>
    	<link rel="dns-prefetch" href="//t3.baidu.com"/>
    	<link rel="dns-prefetch" href="//t10.baidu.com"/>
    	<link rel="dns-prefetch" href="//t11.baidu.com"/>
    	<link rel="dns-prefetch" href="//t12.baidu.com"/>
    	<link rel="dns-prefetch" href="//b1.bdstatic.com"/>
        
        <title>ç™¾åº¦ä¸€ä¸‹ï¼Œä½ å°±çŸ¥é“</title>
        
    
    <style id="css_index" index="index" type="text/css">html,body{height:100%}
    html{overflow-y:auto}
    body{font:12px arial;text-align:;background:#fff}
    body,p,form,ul,li{margin:0;padding:0;list-style:none}
    body,form,#fm{position:relative}
    td{text-align:left}
    img{border:0}
    a{color:#00c}
    a:active{color:#f60}
    input{border:0;padding:0}
    #wrapper{position:relative;_position:;min-height:100%}
    #head{padding-bottom:100px;text-align:center;*z-index:1}
    #ftCon{height:50px;position:absolute;bottom:47px;text-align:left;width:100%;margin:0 auto;z-index:0;overflow:hidden}
    .ftCon-Wrapper{overflow:hid
```   

**å°†çˆ¬è™«ç¨‹åºä¼ªè£…ä¸ºç§»åŠ¨ç‰ˆ chrome æµè§ˆå™¨**


```python
import urllib.request

url = "http://www.baidu.com"
headers = {'User-Agent':'Mozilla/5.0(Linux;U;Android2.2.1;zh-cn;HTC_Wildfire_A3333Build/FRG83D)AppleWebKit/533.1(KHTML,likeGecko)Version/4.0MobileSafari/533.1'}
request = urllib.request.Request(url,headers=headers)

with urllib.request.urlopen(request) as r:
    print(r.read()[500:2000].decode('utf-8')) 

```  

**å°†çˆ¬è™«ç¨‹åºä¼ªè£…ä¸ºç§»åŠ¨ç‰ˆ QQ æµè§ˆå™¨**


```python
import urllib.request

url = "http://www.baidu.com"
headers = {'User-Agent':'MQQBrowser/26Mozilla/5.0(Linux;U;Android2.3.7;zh-cn;MB200Build/GRJ22;CyanogenMod-7)AppleWebKit/533.1(KHTML,likeGecko)Version/4.0MobileSafari/533.1'}
request = urllib.request.Request(url,headers=headers)

with urllib.request.urlopen(request) as r:
    print(r.read()[500:2000].decode('utf-8')) 
```   

**3 ä½¿ç”¨GETæˆ–POSTæ–¹æ³•ï¼Œå‘æœåŠ¡å™¨ä¼ é€’å‚æ•°**

ä¸‹é¢æˆ‘ä»¬å°è¯•ä½¿ç”¨urllibï¼Œå®Œæˆæœ¬è®²çš„ç¬¬3ä¸ªä»»åŠ¡ã€‚

æµè§ˆå™¨æˆ–ç½‘ç»œçˆ¬è™«ç­‰å®¢æˆ·ç«¯ï¼Œåœ¨æŸ¥è¯¢ç½‘ç«™ä¿¡æ¯æˆ–å®ç°ç”¨æˆ·ç™»å½•æ—¶ï¼Œéœ€è¦ä½¿ç”¨GETæ–¹æ³•æˆ–POSTæ–¹æ³•å®ç°æ•°æ®çš„ä¼ é€’ã€‚

**3.1 å‘æœåŠ¡å™¨ä¼ é€’GETæ–¹æ³•å‚æ•°**

é¦–å…ˆåˆ†æä¸€ä¸‹æµè§ˆå™¨ä¸Šä½¿ç”¨ç™¾åº¦æœç´¢å…³é”®å­—çš„è¿‡ç¨‹ã€‚

ä»¥æœç´¢â€œåŒ—äº¬â€å…³é”®å­—ä¸ºä¾‹ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°è¯•ä½¿ç”¨çˆ¬è™«ç¨‹åºå®Œæˆç™¾åº¦æœç´¢ï¼Œå³åˆ©ç”¨Getæ–¹æ³•å‘baiduæäº¤æŸ¥è¯¢è¯·æ±‚ï¼Œç„¶åè·å–ç™¾åº¦çš„æŸ¥è¯¢ç»“æœã€‚


```python
"""ä½¿ç”¨GETæ–¹æ³•ï¼Œå‘ç™¾åº¦æœåŠ¡å™¨å‘é€æŸ¥è¯¢è¯·æ±‚
"""
import urllib.request
import urllib.parse

url = 'http://www.baidu.com/s?'
querystr = {'wd':'åŒ—äº¬'}
querystr_encode = urllib.parse.urlencode(querystr)
print(querystr_encode)
#https://www.baidu.com/s?wd=%E5%8C%97%E8%88%AA
theurl = url + querystr_encode
print(theurl)
headers = {'Accept':'text/html',
           'User-Agent':'Mozilla/5.0',
          }
request = urllib.request.Request(theurl,headers=headers)
with urllib.request.urlopen(request) as response:
    if response.status == 200:
        print(response.read()[500:].decode('utf-8'))

# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    wd=%E5%8C%97%E4%BA%AC
    http://www.baidu.com/s?wd=%E5%8C%97%E4%BA%AC
          <link rel="icon" sizes="any" mask href="//www.baidu.com/img/baidu_85beaf5496f291521eb75ba38eacbd87.svg">
            <link rel="search" type="application/opensearchdescription+xml" href="/content-search.xml" title="ç™¾åº¦æœç´¢" />
    		
    		
    <title>åŒ—äº¬_ç™¾åº¦æœç´¢</title>
    ......
    
    <div class="opr-recommends-merge-content">
     
    	<div class="cr-title c-clearfix">
                <a class="cr-title-sub opr-recommends-merge-more-btn" href="javascript:;" onclick="return false;" data-click="{'fm':'beha'}"><span>å±•å¼€</span><i class="c-icon c-icon-chevron-bottom c-gap-left-small"></i></a>     
            <span title="åŒ—äº¬è‘—åæ™¯ç‚¹">åŒ—äº¬è‘—åæ™¯ç‚¹</span>
                </div>
            ......
        <div class="c-span4  opr-recommends-merge-item " data-click="{'rsv_re_ename':'æ•…å®«','rsv_re_uri':'704c8070baf9434086e533e61da9f2eb'}">
                                                    	<div class="opr-recommends-merge-p">
                <a target="_blank" href="/s?wd=%E6%95%85%E5%AE%AB&usm=4&ie=utf-8&rsv_cq=%E5%8C%97%E4%BA%AC&rsv_dl=0_right_recommends_merge_20826&amp;cq=%E5%8C%97%E4%BA%AC&amp;srcid=20910&amp;rt=%E5%8C%97%E4%BA%AC%E8%91%97%E5%90%8D%E6%99%AF%E7%82%B9&amp;recid=20826&amp;euri=704c8070baf9434086e533e61da9f2eb"><img data-src="http://t10.baidu.com/it/u=1408384650,3025810379&amp;fm=58" data-b64-id="1408384650_3025810379_58" class="c-img c-img4 opr-recommends-merge-img"/></a>
                <a class="opr-recommends-merge-mask" target="_blank" href="/s?wd=%E6%95%85%E5%AE%AB&usm=4&ie=utf-8&rsv_cq=%E5%8C%97%E4%BA%AC&rsv_dl=0_right_recommends_merge_20826&amp;cq=%E5%8C%97%E4%BA%AC&amp;srcid=20910&amp;rt=%E5%8C%97%E4%BA%AC%E8%91%97%E5%90%8D%E6%99%AF%E7%82%B9&amp;recid=20826&amp;euri=704c8070baf9434086e533e61da9f2eb"></a>                    </div>
            <div class="c-gap-top-small"><a target="_blank" title="æ•…å®«" href="/s?wd=%E6%95%85%E5%AE%AB&usm=4&ie=utf-8&rsv_cq=%E5%8C%97%E4%BA%AC&rsv_dl=0_right_recommends_merge_20826&amp;cq=%E5%8C%97%E4%BA%AC&amp;srcid=20910&amp;rt=%E5%8C%97%E4%BA%AC%E8%91%97%E5%90%8D%E6%99%AF%E7%82%B9&amp;recid=20826&amp;euri=704c8070baf9434086e533e61da9f2eb">æ•…å®«</a></div>
                            <div class="opr-recommends-merge-d">
            	            	<p class="opr-recommends-merge-width-text">æ˜æ¸…ä¸¤ä»£çš„çš‡å®«</p>
                        </div>
                                </div>   
    
    </html>
```    

**3.2 å‘æœåŠ¡å™¨ä¼ é€’ POST æ–¹æ³• å‚æ•°**

é¦–å…ˆåˆ†æä¸€ä¸‹æµè§ˆå™¨ä¸Šä½¿ç”¨ç™¾åº¦ç¿»è¯‘çš„æƒ…å†µã€‚

æˆ‘ä»¬ä»¥è®¿é—® http://xwqy.gsxt.gov.cn/etps/productInfoList.do ç½‘ç«™ä¸ºä¾‹ã€‚åœ¨æŸ¥è¯¢é‡‘èæœåŠ¡ä¿¡æ¯æ—¶ä¼šä½¿ç”¨postæ–¹æ³•ä¼ é€’ä¿¡æ¯ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æµè§ˆå™¨çš„å¼€å‘è€…æ¨¡å¼è¿›è¡Œè§‚å¯Ÿè¿™ä¸€è¿‡ç¨‹ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°è¯•ä½¿ç”¨çˆ¬è™«ç¨‹åºè·å–æŸ¥è¯¢ç»“æœï¼Œå³åˆ©ç”¨POSTæ–¹æ³•å‘ http://xwqy.gsxt.gov.cn/etps/productInfoList.do æäº¤æŸ¥è¯¢è¯·æ±‚ï¼Œç„¶åè·å–
æŸ¥è¯¢çš„ç»“æœã€‚


```python
import urllib.request
import urllib.parse

url ='http://xwqy.gsxt.gov.cn/etps/productInfoList.do'
#url = 'https://fanyi.baidu.com/v2transapi'
payload = {'loanQuota': '100ä¸‡å…ƒåŠä»¥ä¸‹'}

payload_encode = urllib.parse.urlencode(payload).encode('utf-8')
print(payload_encode)

headers = {'Accept':'text/html',
           'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}
request = urllib.request.Request(url,headers=headers,data = payload_encode,method='POST')
r= urllib.request.urlopen(request) 
with urllib.request.urlopen(request) as response:
    if response.status == 200:
        rf = response.read()
        print(rf.decode('utf-8'))

```
```
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1" />
        <title>å°å¾®ä¼ä¸šåå½•</title>
    
    <base href="http://xwqy.gsxt.gov.cn/" />
    ......
        			<div class="clist"> <span class="xdtag">æŠµæŠ¼</span>
    			        <h3><a href="javascript:" onclick="funcApp('000000006a1eee1c016a49b50d9201aa')" title="å°å¾®ä¼ä¸šç½‘ç»œè´·æ¬¾">å°å¾®ä¼ä¸šç½‘ç»œè´·æ¬¾</a></h3>
    			        <div class="cs">
    			        	<strong>1-500ä¸‡å…ƒ</strong>
    			        	<i>è´·æ¬¾åˆ©ç‡<b>4.35-8.00%</b></i>
    			        	<span>è´·æ¬¾æœŸé™ï¼š1å¹´ä»¥ä¸‹ï¼ˆå«1å¹´ï¼‰</span>
    			        	<span>è´·æ¬¾é“¶è¡Œï¼šä¸­å›½å·¥å•†é“¶è¡Œ</span>
    			        </div>
    			        <div class="sqbox">
    			          <input type="submit" onclick="appPage('000000006a1eee1c016a49b50d9201aa');return false;"  value="æˆ‘è¦ç”³è¯·">
    			        </div>
    			    </div>
        			
        			<div class="clist"> <span class="xdtag">ä¿¡ç”¨</span>
    			        <h3><a href="javascript:" onclick="funcApp('0000000065f68eaa0166242584b50139')" title="å°å¾®å¿«è´·-ä¿¡ç”¨å¿«è´·">å°å¾®å¿«è´·-ä¿¡ç”¨å¿«è´·</a></h3>
    			        <div class="cs">
    			        	<strong>1-200ä¸‡å…ƒ</strong>
    			        	<i>è´·æ¬¾åˆ©ç‡<b>5.44-5.44%</b></i>
    			        	<span>è´·æ¬¾æœŸé™ï¼š1å¹´ä»¥ä¸‹ï¼ˆå«1å¹´ï¼‰</span>
    			        	<span>è´·æ¬¾é“¶è¡Œï¼šä¸­å›½å»ºè®¾é“¶è¡Œ</span>
    			        </div>
    			        <div class="sqbox">
    			          <input type="submit" onclick="appPage('0000000065f68eaa0166242584b50139');return false;"  value="æˆ‘è¦ç”³è¯·">
    			        </div>
    			    </div>			
        		
    </body>
    </html>
    </div>
    <div class="footer">
    	 <p>ç‰ˆæƒæ‰€æœ‰ï¼šå›½å®¶å¸‚åœºç›‘ç£ç®¡ç†æ€»å±€</p>
    	 <p>åœ°å€ï¼šåŒ—äº¬å¸‚è¥¿åŸåŒºä¸‰é‡Œæ²³ä¸œè·¯å…«å·&nbsp;&nbsp;é‚®æ”¿ç¼–ç ï¼š100820&nbsp;&nbsp;æŠ€æœ¯æ”¯æŒç”µè¯ï¼š010-88650856</p>
    </div>
    </body>
    </html>
```

**4 å¸¸è§å¼‚å¸¸å¤„ç†**

ä¸‹é¢æˆ‘ä»¬æ¥å°è¯•ä½¿ç”¨urllibå®Œæˆæœ¬è®²çš„ç¬¬4ä¸ªä»»åŠ¡ï¼Œå³å¤„ç†å¼‚å¸¸ã€‚

ç½‘ç»œçˆ¬è™«åˆ©ç”¨ç½‘ç»œè·å–æ•°æ®ï¼Œè€Œç½‘ç»œé€šä¿¡ä¸­éš¾å…ä¼šæœ‰å¼‚å¸¸ï¼Œæ‰€ä»¥è¦æƒ³ä½¿çˆ¬è™«ç¨‹åºå˜å¾—å¥å£®å°±éœ€è¦å¼•å…¥å¼‚å¸¸å¤„ç†æœºåˆ¶ã€‚

é¦–å…ˆçœ‹ä¸€ä¸ªæ²¡æœ‰å¼‚å¸¸å¤„ç†çš„ä¾‹å­ï¼š


```python
import urllib.request
import urllib.parse

url ='http://www.google.com/'
headers = {'Accept':'text/html',
           'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}


request = urllib.request.Request(url,headers=headers)

with urllib.request.urlopen(request) as response:
    if response.status == 200:
        rf = response.read()
        print(rf.decode('utf-8'))
```
```
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ

    ---------------------------------------------------------------------------

    TimeoutError                              Traceback (most recent call last)

    D:\pythonspace\anaconda3\lib\urllib\request.py in do_open(self, http_class, req, **http_conn_args)
       1316                 h.request(req.get_method(), req.selector, req.data, headers,
    -> 1317                           encode_chunked=req.has_header('Transfer-encoding'))
       1318             except OSError as err: # timeout error
    

    D:\pythonspace\anaconda3\lib\http\client.py in request(self, method, url, body, headers, encode_chunked)
       1228         """Send a complete request to the server."""
    -> 1229         self._send_request(method, url, body, headers, encode_chunked)
       1230 
    
    ......

    D:\pythonspace\anaconda3\lib\urllib\request.py in do_open(self, http_class, req, **http_conn_args)
       1317                           encode_chunked=req.has_header('Transfer-encoding'))
       1318             except OSError as err: # timeout error
    -> 1319                 raise URLError(err)
       1320             r = h.getresponse()
       1321         except:
    

    URLError: <urlopen error [WinError 10060] ç”±äºè¿æ¥æ–¹åœ¨ä¸€æ®µæ—¶é—´åæ²¡æœ‰æ­£ç¡®ç­”å¤æˆ–è¿æ¥çš„ä¸»æœºæ²¡æœ‰ååº”ï¼Œè¿æ¥å°è¯•å¤±è´¥ã€‚>
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°è¯•å¼•å…¥å¼‚å¸¸å¤„ç†æœºåˆ¶ã€‚


```python
import urllib.request
import urllib.parse

url ='http://www.google.com/'
headers = {'Accept':'text/html',
           'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}

try:
    request = urllib.request.Request(url,headers=headers)

    with urllib.request.urlopen(request) as response:
        if response.status == 200:
            rf = response.read()
            print(rf.decode('utf-8'))
except urllib.error.URLError as e:
    print(e)

```
```
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ
    <urlopen error [WinError 10060] ç”±äºè¿æ¥æ–¹åœ¨ä¸€æ®µæ—¶é—´åæ²¡æœ‰æ­£ç¡®ç­”å¤æˆ–è¿æ¥çš„ä¸»æœºæ²¡æœ‰ååº”ï¼Œè¿æ¥å°è¯•å¤±è´¥ã€‚>
```   

æˆ‘ä»¬è¿˜å¯ä»¥ä½¿è‡ªå·±çš„ç¨‹åºæ›´ä¸“ä¸šä¸€äº›ï¼Œå°†å¼‚å¸¸ä¿¡æ¯ä¸ä»…æ˜¾ç¤ºåœ¨æ§åˆ¶å°ä¸Šï¼Œè¿˜å°†å…¶å­˜å…¥æ—¥å¿—æ–‡ä»¶ã€‚

æ³¨æ„ï¼Œæ­¤æ—¶è¦ä½¿jupyter notebookæœ‰æƒé™å†™æ–‡ä»¶ã€‚


```python
import urllib.request
import urllib.error
import urllib.parse
import logging


logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S',
                    filename='.\log\mycrawler.log',
                    level=logging.DEBUG,decode='utf-8')


try:
    
    import socket
    # timeout in seconds
    timeout = 3
    socket.setdefaulttimeout(timeout)
    
    url ='http://www.google.com/'
    headers = {'Accept':'text/html',
           'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'}

    request = urllib.request.Request(url,headers=headers)
    with urllib.request.urlopen(request) as response:
        print(response.status)
        print(response.read().decode('utf-8'))
except urllib.error.HTTPError as e:
    import http.server
    #print(http.server.BaseHTTPRequestHandler.responses[e.code])
    logging.error('HTTPError code: %s and Messages: %s'% (str(e.code),http.server.BaseHTTPRequestHandler.responses[e.code]))
    logging.info('HTTPError headers: ' + str(e.headers))
    logging.info(e.read().decode('utf-8'))
    print('ä¸å¥½æ„æ€ï¼ŒæœåŠ¡å™¨å¡å£³å„¿äº†ï¼Œè¯·ç¨åé‡è¯•ã€‚è¯¦ç»†ä¿¡æ¯å¯ä»¥æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ã€‚')
except urllib.error.URLError as e:
    logging.error(e.reason)
    print('ä¸å¥½æ„æ€ï¼ŒæœåŠ¡å™¨å¡å£³å„¿äº†ï¼Œè¯·ç¨åé‡è¯•ã€‚è¯¦ç»†ä¿¡æ¯å¯ä»¥æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ã€‚')
```

#### æ¡ˆä¾‹

è§ç¬¬ä¸‰ç« æ¡ˆä¾‹1

#### ä¹ é¢˜

è§ä¹ é¢˜é›†

#### å†…å®¹å°ç»“

æœ¬å°èŠ‚ä¸»è¦ä»‹ç»äº†ï¼š

- Anacondaçš„å®‰è£…ä½¿ç”¨
- Urllibåº“åŸºæœ¬æƒ…å†µ
- urllib.request.urlopen()çš„åŸºæœ¬ç”¨æ³•
- ç»“åˆ4ä¸ªä»»åŠ¡ä»‹ç»äº†å®ç°Webé¡µé¢çˆ¬å–çš„åŸºæœ¬è¿‡ç¨‹å’Œç»†èŠ‚ã€‚

### 3 ä½¿ç”¨Python Requestsä¼˜åŒ–é¡µé¢çˆ¬å–è¿‡ç¨‹

ä½¿ç”¨urllibåº“å¯ä»¥å®ç°åŒ…æ‹¬è®¿é—®URLã€ä¼ é€’å‚æ•°ã€è®¾ç½®ä»£ç†ã€è¿›è¡Œèº«ä»½è®¤è¯ç­‰åŠŸèƒ½ï¼Œä½†å®ƒçš„ä¸€äº›æ“ä½œä¸å¤ªç®€æ´ã€‚ä¸ºäº†ä½¿æˆ‘ä»¬çš„çˆ¬è™«ç¨‹åºæ›´åŠ ä¼˜é›…ï¼Œæˆ‘ä»¬ä¸‹é¢ä»‹ç»å¦ä¸€ä¸ªPythonåº“ ï¼šrequestsåº“ï¼Œä½¿ç”¨å®ƒä½¿é¡µé¢çˆ¬å–è¿‡ç¨‹æ›´åŠ ä¼˜åŒ–ã€‚

#### çŸ¥è¯†è®²è§£

Requestsåº“åŸºäºurllibåº“ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªç”¨äºå¤„ç†URLçš„å·¥å…·åº“ã€‚ä½¿ç”¨å®ƒæ¯”urllibæ›´åŠ ç®€æ´ã€‚å®ƒçš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š

- èƒ½å¤Ÿè‡ªåŠ¨ä¿æŒä¸ç½‘ç«™çš„TCPè¿æ¥ï¼Œ
- å†…å«å¸¦æŒä¹…cookieçš„ä¼šè¯æœºåˆ¶ï¼Œ
- èƒ½å¤Ÿæä¾›åƒæµè§ˆå™¨ç±»ä¼¼çš„SSLè®¤è¯ï¼Œ
- èƒ½å¤Ÿè‡ªåŠ¨å®Œæˆå†…å®¹è§£ç ï¼Œ
- èƒ½å¤Ÿæ”¯æŒæ–‡ä»¶åˆ†å—ä¸Šä¼ å’Œæµå¼ä¸‹è½½ï¼Œ
- èƒ½å¤Ÿè‡ªåŠ¨å¯¹ä¸‹è½½å›¾ç‰‡ã€æ–‡ä»¶çš„è§£å‹ï¼Œ
- æ”¯æŒUnicodeå“åº”ç»“æœç­‰ç­‰ã€‚

ä¸‹é¢æˆ‘ä»¬å°†ä½¿ç”¨requestsï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. æ„å»ºrequestsçˆ¬è™«ç¨‹åºæ¡†æ¶ï¼Œå®Œæˆå¯¹æŒ‡å®šURLçš„è®¿é—®ï¼Œè·å–å¹¶åˆ†æå“åº”ç»“æœï¼›
2. å®šåˆ¶httpè¯·æ±‚å¤´ï¼Œå®Œæˆå¤æ‚POSTè¯·æ±‚å’Œå“åº”ï¼›
3. ä½¿ç”¨requestå¤„ç†cookieï¼Œä½¿ç”¨requestsä¼šè¯å¯¹è±¡ï¼›
4. è®¾ç½®ä»£ç†æœåŠ¡å™¨
5. è®¾ç½®SSLè¯ä¹¦éªŒè¯

**å®‰è£…requestsåº“**

é¦–å…ˆä»‹ç»requestsåº“çš„å®‰è£…è¿‡ç¨‹ã€‚

1. å¤§å®¶å¯åŠ¨anaconda promptï¼›
2. ç¡®ä¿è‡ªå·±çš„ç”µè„‘èƒ½è®¿é—®äº’è”ç½‘ï¼›
3. åœ¨æ‰“å¼€çš„å‘½ä»¤è¡Œä¸‹é”®å…¥å¦‚ä¸‹å‘½ä»¤ï¼š

> pip install requests

4. å®‰è£…è¿‡ç¨‹ä¸€èˆ¬ä¸ä¼šæœ‰å¼‚å¸¸ï¼Œå®‰è£…ç»“æŸåå¯åŠ¨jupyter notebookï¼Œè¿è¡Œä¸‹åˆ—ä»£ç ï¼Œæµ‹è¯•requestsåº“æ˜¯å¦å¯ä»¥æ­£å¸¸å¯¼å…¥ï¼›
5. å¦‚æœæ²¡æœ‰é—®é¢˜ï¼Œåˆ™å®‰è£…æˆåŠŸï¼›å¦åˆ™ï¼Œå¯ä»¥è€ƒè™‘é‡æ–°æ‰§è¡Œä¸Šè¿°æ­¥éª¤ã€‚


```python
import requests

help(requests)
```
```
# ä»¥ä¸‹ä¸ºéƒ¨åˆ†æ‰§è¡Œç»“æœ
    Help on package requests:
    
    NAME
        requests
    
    DESCRIPTION
        Requests HTTP Library
        ~~~~~~~~~~~~~~~~~~~~~
        
        Requests is an HTTP library, written in Python, for human beings. Basic GET
        usage:
        
           >>> import requests
           >>> r = requests.get('https://www.python.org')
           >>> r.status_code
           200
           >>> 'Python is a programming language' in r.content
           True
        
        ... or POST:
        
           >>> payload = dict(key1='value1', key2='value2')
           >>> r = requests.post('https://httpbin.org/post', data=payload)
           >>> print(r.text)
           {
             ...
             "form": {
               "key2": "value2",
               "key1": "value1"
             },
             ...
           }
        
        The other HTTP methods are supported - see `requests.api`. Full documentation
        is at <http://python-requests.org>.
        
        :copyright: (c) 2017 by Kenneth Reitz.
        :license: Apache 2.0, see LICENSE for more details.
    
    PACKAGE CONTENTS
        __version__
        _internal_utils
        adapters
        api
        auth
        certs
        compat
        cookies
        exceptions
        help
        hooks
        models
        packages
        sessions
        status_codes
        structures
        utils
    
    FUNCTIONS
        check_compatibility(urllib3_version, chardet_version)
    
    DATA
        __author_email__ = 'me@kennethreitz.org'
        __build__ = 139520
        __cake__ = 'âœ¨ ğŸ° âœ¨'
        __copyright__ = 'Copyright 2018 Kenneth Reitz'
        __description__ = 'Python HTTP for Humans.'
        __license__ = 'Apache 2.0'
        __title__ = 'requests'
        __url__ = 'http://python-requests.org'
        codes = <lookup 'status_codes'>
        cryptography_version = '2.4.2'
    
    VERSION
        2.21.0
    
    AUTHOR
        Kenneth Reitz
    
    FILE
        d:\pythonspace\anaconda3\lib\site-packages\requests\__init__.py
    
```  
    

**åˆè¯†requestsåº“**

requestsåº“æ˜¯ä¸€ä¸ªpythonè¯­è¨€ç¼–å†™çš„httpå·¥å…·åº“ï¼Œå®ƒåŸºäºurllibï¼Œä½†æ¯”urllibæ›´åŠ æ˜“ç”¨ã€‚

æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯ï¼Œå¯ä»¥çœ‹åˆ°requestsåº“çš„æ˜¯ä½¿ç”¨æ–¹æ³•ååˆ†ç®€å•ã€‚

ä¸‹é¢ï¼Œæˆ‘ä»¬ç»“åˆæœ¬è®²çš„ä»»åŠ¡ï¼Œä¸¾ä¾‹è¯´æ˜requestsçš„ä½¿ç”¨æ–¹æ³•ã€‚

#### 3.1 æ„å»ºrequestsçˆ¬è™«ç¨‹åºæ¡†æ¶ï¼Œå®Œæˆå¯¹æŒ‡å®šURLçš„è®¿é—®ï¼Œè·å–å¹¶åˆ†æå“åº”ç»“æœã€‚

```python
import requests

r = requests.get('https://www.baidu.com')
print("å“åº”ç ï¼š")
print(r.status_code)
print("å“åº”å†…å®¹ï¼š")
print(r.text)
```


å¯ä»¥çœ‹åˆ°ä¸Šé¢çš„å“åº”å†…å®¹ä¸­å­˜åœ¨ä¸€äº›ä¸å¯è¯»çš„ç¼–ç ï¼Œæˆ‘ä»¬éœ€è¦åšä¸€äº›ç¼–ç è½¬æ¢ã€‚è€Œä¸”ä¸Šé¢çš„ä»£ç è¿‡äºç®€å•ï¼Œä¸èƒ½é˜²æ­¢å¼‚å¸¸çš„å‘ç”Ÿï¼Œæˆ‘ä»¬è¿˜éœ€è¦å¼•å…¥ä¸€å®šçš„å¼‚å¸¸å¤„ç†æœºåˆ¶ã€‚

ä¸‹é¢ï¼Œæˆ‘ä»¬æ„å»ºä¸€ä¸ªåˆ©ç”¨requestè®¿é—®urlçš„å‡½æ•°ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä»Šåçš„ç½‘ç»œçˆ¬è™«ç¨‹åºä¸­èƒ½å¤Ÿå¤ç”¨å®ƒã€‚


```python
def fetchUrl(url):
    try:
        r = requests.get(url)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text

    except:
        return "Some exceptions were raised."

url = "https://www.baidu.com"
fetchUrl(url)
```

**ç†è§£å“åº”å¯¹è±¡**

ä¸Šé¢çš„å¤„ç†ï¼Œä½¿ç”¨äº†å“åº”å¯¹è±¡çš„è‹¥å¹²æ–¹æ³•å’Œå±æ€§ã€‚ä¸‹é¢å†ä»‹ç»ä¸€äº›æœ‰å…³rquestså“åº”å¯¹è±¡çš„çŸ¥è¯†ã€‚



```python
"""ç†è§£å“åº”"""
import requests

r = requests.get('http://api.github.com/events')

print("å“åº”çŠ¶æ€ç ï¼š")
print(r.status_code)
print('å“åº”å¤´ä¿¡æ¯ï¼š')
print(r.headers)
print('å“åº”å†…å®¹ç¼–ç æ ¼å¼ï¼š')
print(r.encoding)
print('cookieï¼š')
print(r.cookies)
print("é‡å®šå‘ä¸å†å²:")
print(r.history)
print("è®¿é—®çš„url:")
print(r.url)
```

    å“åº”çŠ¶æ€ç ï¼š
    200
    å“åº”å¤´ä¿¡æ¯ï¼š
    {'Date': 'Thu, 11 Jul 2019 07:31:08 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Server': 'GitHub.com', 'Status': '200 OK', 'X-RateLimit-Limit': '60', 'X-RateLimit-Remaining': '59', 'X-RateLimit-Reset': '1562833868', 'Cache-Control': 'public, max-age=60, s-maxage=60', 'Vary': 'Accept, Accept-Encoding', 'ETag': 'W/"c27290afefb1a02c1b93fda1ff461b74"', 'Last-Modified': 'Thu, 11 Jul 2019 07:26:08 GMT', 'X-Poll-Interval': '60', 'X-GitHub-Media-Type': 'github.v3; format=json', 'Link': '<https://api.github.com/events?page=2>; rel="next", <https://api.github.com/events?page=10>; rel="last"', 'Access-Control-Expose-Headers': 'ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type', 'Access-Control-Allow-Origin': '*', 'Strict-Transport-Security': 'max-age=31536000; includeSubdomains; preload', 'X-Frame-Options': 'deny', 'X-Content-Type-Options': 'nosniff', 'X-XSS-Protection': '1; mode=block', 'Referrer-Policy': 'origin-when-cross-origin, strict-origin-when-cross-origin', 'Content-Security-Policy': "default-src 'none'", 'Content-Encoding': 'gzip', 'X-GitHub-Request-Id': '2754:6B16:62C393:838D64:5D26E5BB'}
    å“åº”å†…å®¹ç¼–ç æ ¼å¼ï¼š
    utf-8
    cookieï¼š
    <RequestsCookieJar[]>
    é‡å®šå‘ä¸å†å²:
    [<Response [301]>]
    è®¿é—®çš„url:
    https://api.github.com/events
    

#### 3.2 å®šåˆ¶httpè¯·æ±‚å¤´ï¼Œå®Œæˆå¤æ‚POSTè¯·æ±‚å’Œå“åº”


ä½¿ç”¨requestsåº“è®¿é—®urlæ—¶ï¼Œæˆ‘ä»¬çš„çˆ¬è™«ç¨‹åºä½œä¸ºå®¢æˆ·ç«¯ï¼Œå…¶user-agentå€¼ä¸ºpython-requests/2.21.0ï¼Œè¿™ä¸€ç‚¹æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¿é—®httpbinçš„user-agenté¡µé¢è¿›è¡ŒéªŒè¯ã€‚


```python
import requests

url = "http://www.httpbin.org/user-agent"
with requests.get(url) as r:
    print(r.text)
```

    {
      "user-agent": "python-requests/2.21.0"
    }
    
    

ä¸ºäº†ä½¿çˆ¬è™«ç¨‹åºå€Ÿç”¨æµè§ˆå™¨çš„user-agentï¼Œä½¿å…¶æ›´åƒæµè§ˆå™¨ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹åˆ—æ–¹æ³•å®šåˆ¶httpè¯·æ±‚å¤´ã€‚


```python
import requests

def fetchUrl(url):
    try:
        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
                  }
        r = requests.get(url,headers=headers)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text

    except:
        return "Some exceptions were raised."

url = "http://www.httpbin.org/user-agent"
fetchUrl(url)
```




    '{\n  "user-agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36"\n}\n'



å¦‚ä½•ä½¿ç”¨requestsåº“å‘ç½‘ç«™æœåŠ¡å™¨æäº¤ä¿¡æ¯å‘¢ï¼Ÿ

#### 3.3 ä½¿ç”¨GETå’ŒPOSTæ–¹æ³•æäº¤ä¿¡æ¯

**ä½¿ç”¨GETæ–¹æ³•æäº¤ä¿¡æ¯**

```python
import requests

def fetchUrl(url,querystr):
    try:
        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
                  }
        queryload = {'wd':querystr}
        r = requests.get(url,params = queryload,headers = headers)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text

    except:
        return "Some exceptions were raised."

url = 'http://www.baidu.com/s?'

fetchUrl(url,'åŒ—äº¬')
```

**ä½¿ç”¨POSTæ–¹æ³•æäº¤ä¿¡æ¯**

```python
import requests

def fetchUrl(url,queryload):
    try:
        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
                  }
        
        r = requests.post(url,data = queryload,headers = headers)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text

    except requests.exceptions.HTTPError as e:
        print(e)
        return "Some exceptions were raised."
    

url = ' http://xwqy.gsxt.gov.cn/etps/productInfoList.do '
payload = {'loanQuota': '100ä¸‡å…ƒåŠä»¥ä¸‹'}
fetchUrl(url,payload)
```


#### 3.4 ä½¿ç”¨requestsä¼šè¯å¯¹è±¡ä¿å­˜å’Œä¼ é€’cookies

cookieæ˜¯ç½‘ç«™ä¸ºäº†è¾¨åˆ«ç”¨æˆ·èº«ä»½ã€è¿›è¡Œä¼šè¯è·Ÿè¸ªè€Œå‚¨å­˜åœ¨ç”¨æˆ·æœ¬åœ°ç«¯å’ŒæœåŠ¡å™¨ä¸Šçš„æ•°æ®ã€‚

ä¸‹é¢çš„ä»£ç æ˜¾ç¤ºäº†è®¿é—®www.baidu.com æ—¶ï¼Œç™¾åº¦æœåŠ¡å™¨ç”Ÿæˆçš„cookieå€¼ã€‚


```python
import requests

def fetchUrl(url):
    try:
        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
                  }
        
        r = requests.get(url,headers = headers)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        
        return print(r.cookies)

    except:
        return "Some exceptions were raised."


url = 'https://tieba.baidu.com/index.html'

fetchUrl(url)
```

å¾ˆå¤šç½‘ç«™æœåŠ¡å™¨æä¾›ç»™å·²ç™»å½•ç”¨æˆ·å’Œæœªç™»å½•ç”¨æˆ·çš„ä¿¡æ¯æ˜¯ä¸åŒçš„ã€‚è€Œè®°å½•ç”¨æˆ·çŠ¶æ€çš„æ˜¯cookiesã€‚

ä¸ºäº†ä½¿ç”¨çˆ¬è™«ç¨‹åºè®¿é—®å·²ç™»å½•ç”¨æˆ·æ‰èƒ½æµé‡çš„ç½‘é¡µï¼Œæˆ‘ä»¬å¯ä»¥é‡‡å–ä»¥ä¸‹ç­–ç•¥ï¼š
1. æ‰‹åŠ¨ç™»å½•æŸä¸ªç½‘ç«™ï¼›
2. é€šè¿‡æµè§ˆå™¨å¼€å‘è€…æ¨¡å¼ï¼Œè·å–å½“å‰cookies
3. åœ¨çˆ¬è™«ç¨‹åºä¸­å»ºç«‹Sessionå¯¹è±¡ï¼›
4. ä½¿ç”¨cookiesæ•°æ®æ›´æ–°Sessionå¯¹è±¡çš„cookiesï¼Œä¹‹åå†ä½¿ç”¨çˆ¬è™«è®¿é—®å—ä¿æŠ¤çš„ç½‘é¡µã€‚

æˆ‘ä»¬ä»¥è®¿é—®ç™¾åº¦ä¸ºä¾‹è¯´æ˜è¿™ä¸ªè¿‡ç¨‹ã€‚


```python
import requests

def fetchUrl(url,cookies):
    try:
        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
                  }
        print("æäº¤è¯·æ±‚å‰çš„cookieså€¼ï¼š")
        session = requests.Session()
        session.cookies.update(cookies)
        print(session.cookies)
        r = session.get(url,headers = headers)
        
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        
        print("æœåŠ¡å™¨å“åº”ä¸­çš„cookieså€¼ï¼š")
        print(r.cookies)
        
        return r.text

    except requests.exceptions.HTTPError as e:
        print(e)       
        return "Some exceptions were raised."

url = 'http://i.baidu.com/'

cookies = dict(BAIDUID='3E1B4DE81836633B09BA505869736F3C:FG=1',
               PSTM='1561023988',
               BIDUPSID='E53026ACD99DA573C9474C276849AFFA',
               BDORZ='B490B5EBF6F3CD402E515D22BCDA1598',
               MCITY='-131%3A',
               yjs_js_security_passport='74440fdbd35296135d63011f8d0abe55d5e700f5_1562132807_js',
               BDUSS='GJFdmdPcjVPMUUteVpZcXoybkFsS1ZsMmVTfnFFbGk3YX5SYmhUcm15Slk3RU5kSVFBQUFBJCQAAAAAAAAAAAEAAABz6UcBZmx5YXRvAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhfHF1YXxxdR',
               H_PS_PSSID='1437_21111_29135_29238_28518_29098_28833_29220_29439_20718',
               delPer='0',
               PSINO='1',
               PHPSESSID='rt2292okka0ubt079se46cpp47',
               Hm_lvt_4010fd5075fcfe46a16ec4cb65e02f04='1562139865,1562141343',
               Hm_lpvt_4010fd5075fcfe46a16ec4cb65e02f04='1562141343',)
cookies['BDRCVFR\[feWj1Vr5u3D\]']='I67x6TjHwwYf0'
fetchUrl(url,cookies)
```


#### 3.5 è®¾ç½®ä»£ç†æœåŠ¡å™¨


å¦‚æœéœ€è¦ä½¿ç”¨ä»£ç†ï¼Œä½ å¯ä»¥é€šè¿‡ä¸ºä»»æ„è¯·æ±‚æ–¹æ³•æä¾› proxies å‚æ•°æ¥é…ç½®å•ä¸ªè¯·æ±‚:


```python
import requests

def fetchUrl(url,proxies = None):
    try:
        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
                  }
        if proxies:
            r = requests.get(url,headers = headers,proxies = proxies)
        else:
            r = requests.get(url,headers = headers)
            
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text

    except requests.exceptions.HTTPError as e:
        print(e)
        return "Some exceptions were raised."
    

url = 'http://www.baidu.com'

proxies = {
  "http": "59.108.125.241:8080",
  "http": "47.104.172.108:8118",
}
fetchUrl(url,proxies = proxies)
```

#### 3.6 è®¾ç½®SSLè¯ä¹¦éªŒè¯

Requests å¯ä»¥ä¸º HTTPS è¯·æ±‚éªŒè¯ SSL è¯ä¹¦ï¼Œå°±åƒ web æµè§ˆå™¨ä¸€æ ·ã€‚

SSL éªŒè¯é»˜è®¤æ˜¯å¼€å¯çš„ï¼Œå¦‚æœè¯ä¹¦éªŒè¯å¤±è´¥ï¼ŒRequests ä¼šæŠ›å‡º SSLError.

ä¸‹é¢ä¸¾ä¾‹è¯´æ˜ï¼š


```python
import requests
import os
def fetchUrl(url,cafile):
    try:
        headers = {'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
                   'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36',
                  }
        r = requests.get(url,headers = headers,verify =cafile)
        
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text

    except requests.exceptions.HTTPError as e:
        print(e)
        return "Some exceptions were raised."
    

url = 'https://www.citibank.com.cn/sim/index.htm'

cafile = 'sampleca.cer'
fetchUrl(url,cafile)
```

#### æ¡ˆä¾‹

è§ç¬¬ä¸‰ç« æ¡ˆä¾‹2

#### ä¹ é¢˜

è§ä¹ é¢˜é›†

#### å†…å®¹å°ç»“

æœ¬å°èŠ‚ä¸»è¦ä»‹ç»äº†Requestsåº“çˆ¬å–webé¡µé¢çš„æ–¹æ³•ã€‚

Requestsåº“è¾ƒUrllibåº“æ›´åŠ äººæ€§åŒ–ï¼Œæœ‰åˆ©äºå¿«é€Ÿæ„å»ºWebé¡µé¢è·å–ç¨‹åºã€‚

Requestsåº“çš„åº”ç”¨å…³é”®åœ¨äºç†è§£requests.get()ã€requests.postã€requests.Sessionç­‰æ–¹æ³•æˆ–ç±»çš„åº”ç”¨ã€‚

## æœ¬èŠ‚æ€»ç»“

æœ¬èŠ‚ä¸»è¦ä»‹ç»äº†å¦‚ä½•é€šè¿‡pythonè‡ªå¸¦åº“urllibå’Œç¬¬ä¸‰æ–¹ python httpåº“ requestsæ¥è·å–webé¡µé¢å†…å®¹ã€‚

urllibåº“ä½œä¸ºpythonè‡ªå¸¦çš„httpæ–¹æ³•åº“ï¼Œå¯ä»¥æ„å»ºWebé¡µé¢çˆ¬å–ç¨‹åºã€å¤„ç†å¼‚å¸¸ã€è§£æurlç¼–ç ï¼Œä½†æ“ä½œæ—¶éœ€è¦æ³¨æ„è¾ƒå¤šçš„æŠ€æœ¯ç»†èŠ‚ï¼Œæ–°æ‰‹ä½¿ç”¨æ—¶åº”å¤šæŸ¥çœ‹å¸®åŠ©æ–‡ä»¶ï¼Œä»æ ¹æœ¬ä¸Šå¼„é€šé“ç†ã€‚

requestsåº“æ˜¯åŸºäºurllibçš„httpæ–¹æ³•åº“ï¼Œå®ƒçš„å¯ç”¨æ€§è¾ƒé«˜ï¼Œå¼€å‘é€Ÿåº¦æ›´å¿«ï¼Œå»ºè®®å¤šåŠ ç»ƒä¹ ä½¿ç”¨ã€‚

## è¯¾åç»ƒä¹ 

è§ä¹ é¢˜é›†ã€‚
