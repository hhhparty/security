{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关联分析\n",
    "\n",
    "从大规模数据集中寻找物品间的隐含关系被称作为关联分析（association analysis）和关联规则学习（association rule learning）。\n",
    "\n",
    "关联分析是数据挖掘中一项基础又重要的技术，是一种在大型数据库中发现变量之间有趣关系的方法。说到数据挖掘的案例，相信很多人都会首先想到沃尔玛超市发现购买尿布的顾客通常也会购买啤酒，于是把啤酒和尿布放在一起销售同时提高了两者的销量的案例。\n",
    "\n",
    "这是关联分析在商业领域应用的一个典型，通过对大量商品记录作分析，提取出能够反映顾客偏好的有用的规则。有了这些关联规则，商家制定相应的营销策来来提高销售量。关联技术不但在商业领域被广泛应用，在医疗，保险，电信和证券等领域也得到了有效的应用。本文将对数据挖掘中的关联分析技术做简要的介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念\n",
    "\n",
    "**事务**\n",
    "\n",
    "事务库中的每一条记录被称为一笔事务。在上表的购物篮事务中，每一笔事务都表示一次购物行为。\n",
    "\n",
    "**项集(T)**\n",
    "\n",
    "包含0个或者多个项的集合称为项集。在购物蓝事务中，每一样商品就是一个项，一次购买行为包含了多个项，把其中的项组合起来就构成了项集。\n",
    "\n",
    "**支持度计数**\n",
    "\n",
    "项集在事务中出现的次数。例如，｛Bread，Milk｝这个项集在事务库中一共出现了3次，那么它的支持度计数就是3，。\n",
    "\n",
    "**支持度(s)**\n",
    "\n",
    "包含项集的事务在所有事务中所占的比例：，这里N是所有事务的数量。上面的例子中我们得到了{Bread，Milk}这个项集的支持度计数是3，事物库中一共有5条事务，那么{Bread，Milk}这个项集的支持度就是。\n",
    "\n",
    "**频繁项集**\n",
    "\n",
    "如果我们对项目集的支持度设定一个最小阈值，那么所有支持度大于这个阈值的项集就是频繁项集。\n",
    "\n",
    "**关联规则**\n",
    "\n",
    "关联规则其实是两个项集之间的蕴涵表达式。如果我们有两个不相交的项集X和Y，就可以有规则X→Y, 例如｛Bread，Milk｝→{Diaper}。项集和项集之间组合可以产生很多规则，但不是每个规则都是有用的，我们需要一些限定条件来帮助我们找到强度高的规则。\n",
    "\n",
    "**支持度(s)**\n",
    "\n",
    "关联规则的支持度定义为：也就是同时包含X和Y这两个项集的事务占所有事务的比例。我们看｛Bread，Milk｝→{Diaper}这个例子，同时包含｛Bread，Milk，Diaper}这个项集的事务一共有2项，因此这个规则的支持度是。\n",
    "\n",
    "**置信度(c)**\n",
    "\n",
    "关联规则的置信度定义为：这个定义确定的是Y在包含X的事务中出现的频繁程度。还是看｛Bread，Milk｝→{Diaper}这个例子，包含｛Bread，Milk｝项的事务出现了2次，包含｛Bread，Milk，Diaper}的事务也出现了2次，那么这个规则的置信度就是1。\n",
    "\n",
    "对于关联规则定义这两个度量很有意义的。首先，通过对规则支持度支持度的限定滤去没有意义的规则。我们从商家的角度出发，数据挖掘意义是通过挖掘做出相应的战略决策产生价值。如果一个规则支持度很低，说明顾客同时购买这些商品的次数很少，商家针对这个规则做决策几乎没有意义。其次，置信度越大说明这个规则越可靠。\n",
    "\n",
    "**关联规则发现**\n",
    "\n",
    "有了上述两个度量，就可以对所有规则做限定，找出对我们有意义的规则。首先对支持度和置信度分别设置最小阈值minsup和minconf。然后在所有规则中找出支持度≥minsup和置信度≥minconf的所有关联规则。\n",
    "\n",
    "有一点我们需要注意的是由简单关联规则得出的推论并不包含因果关系。我们只能由A→B得到A与B有明显同时发生的情况，但不能得出A是因，B是果。也就是说我们只能从案例中获得。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关联规则算法\n",
    "\n",
    "根据上面对于关联规则的定义，有一个原始而又简单粗暴粗暴的算法就是，找出所有的规则，对每一个规则计算支持度和置信度，然后再从中提取符合条件的规则。但是这个方法存在一个很致命的问题：如果一个数据集有d个项，这个数据包含的规则总数为：\n",
    "\n",
    "光是一个6个项的数据集产生的规则就有602条，随着项数量的增加，原始算法的复杂度将成级数增长。下面这个格结构常常用来枚举所有规则的可能性。\n",
    "\n",
    "![枚举所有可能性](images/aa/枚举所有可能性.jpeg)\n",
    "\n",
    "因此为了控制需要计算支持度和置信度的规则数量，目前关联规则的挖掘过程大致可以总结为两步：\n",
    "\n",
    "1. 找出所有频繁项集\n",
    "\n",
    "2. 由频繁项集产生规则，从中提取置信度高的规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori算法\n",
    "\n",
    "Apriori算法是第一个关联规则的挖掘算法，它开创性的使用了基于支持度的剪枝技术来控制候选项集的指数级增长。Apriori算法产生频繁项集的过程有两步：第一，逐层找出当前候选项集中的所有频繁项集：第二，用当前长度的频繁项集产生长度加1的新的候选项集。\n",
    "\n",
    "首先我们来看一下Apriori算法用到的核心原理用到的两个重要性质：\n",
    "\n",
    "- 如果一个项集是频繁的，那么它的所有子集都是频繁的。\n",
    "\n",
    "- 如果一个项集是非频繁的，那么它的所有超集都是非平凡的。\n",
    "\n",
    "如果一个项集是非频繁项集，那么这个项集的超集就不需要再考虑了。\n",
    "\n",
    "因为如果这个项集是非频繁的，那么它的所有超集也一定都是非频繁的。\n",
    "\n",
    "在项集的超集是指，包含这个项集的元素且元素个数更多的项集。在购物篮事务库中{Milk,Beer}就是{Milk}的其中一个超集。这个原理很好理解，如果{Milk}出现了3次，{Milk,Beer}一起出现的次数一定小于3次。所以如果一个项集的支持度小于最小支持度这个阈值了，那么它的超集的支持度一定也小于这个阈值，就不用再考虑了。\n",
    "\n",
    "![枚举所有可能性](images/aa/apriori伪代码.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[frozenset({5}), frozenset({2}), frozenset({3})], [frozenset({2, 5})], []] {frozenset({1}): 0.5, frozenset({3}): 0.75, frozenset({4}): 0.25, frozenset({2}): 0.75, frozenset({5}): 0.75, frozenset({2, 5}): 0.75, frozenset({3, 5}): 0.5, frozenset({2, 3}): 0.5}\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "\n",
    "\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "\n",
    "# 获取候选1项集，dataSet为事务集。返回一个list，每个元素都是set集合\n",
    "def createC1(dataSet):\n",
    "    C1 = []   # 元素个数为1的项集（非频繁项集，因为还没有同最小支持度比较）\n",
    "    for transaction in dataSet:\n",
    "        for item in transaction:\n",
    "            if not [item] in C1:\n",
    "                C1.append([item])\n",
    "    C1.sort()  # 这里排序是为了，生成新的候选集时可以直接认为两个n项候选集前面的部分相同\n",
    "    # 因为除了候选1项集外其他的候选n项集都是以二维列表的形式存在，所以要将候选1项集的每一个元素都转化为一个单独的集合。\n",
    "    return list(map(frozenset, C1))   #map(frozenset, C1)的语义是将C1由Python列表转换为不变集合（frozenset，Python中的数据结构）\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 找出候选集中的频繁项集\n",
    "# dataSet为全部数据集，Ck为大小为k（包含k个元素）的候选项集，minSupport为设定的最小支持度\n",
    "def scanD(dataSet, Ck, minSupport):\n",
    "    ssCnt = {}   # 记录每个候选项的个数\n",
    "    for tid in dataSet:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                ssCnt[can] = ssCnt.get(can, 0) + 1   # 计算每一个项集出现的频率\n",
    "    numItems = float(len(dataSet))\n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key] / numItems\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0, key)  #将频繁项集插入返回列表的首部\n",
    "        supportData[key] = support\n",
    "    return retList, supportData   #retList为在Ck中找出的频繁项集（支持度大于minSupport的），supportData记录各频繁项集的支持度\n",
    "\n",
    "\n",
    "# 通过频繁项集列表Lk和项集个数k生成候选项集C(k+1)。\n",
    "def aprioriGen(Lk, k):\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            # 前k-1项相同时，才将两个集合合并，合并后才能生成k+1项\n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]   # 取出两个集合的前k-1个元素\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(Lk[i] | Lk[j])\n",
    "    return retList\n",
    "\n",
    "# 获取事务集中的所有的频繁项集\n",
    "# Ck表示项数为k的候选项集，最初的C1通过createC1()函数生成。Lk表示项数为k的频繁项集，supK为其支持度，Lk和supK由scanD()函数通过Ck计算而来。\n",
    "def apriori(dataSet, minSupport=0.5):\n",
    "    C1 = createC1(dataSet)  # 从事务集中获取候选1项集\n",
    "    D = list(map(set, dataSet))  # 将事务集的每个元素转化为集合\n",
    "    L1, supportData = scanD(D, C1, minSupport)  # 获取频繁1项集和对应的支持度\n",
    "    L = [L1]  # L用来存储所有的频繁项集\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0): # 一直迭代到项集数目过大而在事务集中不存在这种n项集\n",
    "        Ck = aprioriGen(L[k-2], k)   # 根据频繁项集生成新的候选项集。Ck表示项数为k的候选项集\n",
    "        Lk, supK = scanD(D, Ck, minSupport)  # Lk表示项数为k的频繁项集，supK为其支持度\n",
    "        L.append(Lk);supportData.update(supK)  # 添加新频繁项集和他们的支持度\n",
    "        k += 1\n",
    "    return L, supportData\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    dataSet = loadDataSet()  # 获取事务集。每个元素都是列表\n",
    "    # C1 = createC1(dataSet)  # 获取候选1项集。每个元素都是集合\n",
    "    # D = list(map(set, dataSet))  # 转化事务集的形式，每个元素都转化为集合。\n",
    "    # L1, suppDat = scanD(D, C1, 0.5)\n",
    "    # print(L1,suppDat)\n",
    "\n",
    "\n",
    "    L, suppData = apriori(dataSet,minSupport=0.7)\n",
    "    print(L,suppData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
