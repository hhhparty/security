# 第2讲 信息收集类测试

## 使用搜索引擎发现情报和信息泄露 Conduct Search Engine Discovery Reconnaissance for Information Leakage

ID ：WSTG-INFO-001

### Test Objectives

尝试理解主动暴露（官方网站）或被动暴露（第三方网站）的应用、系统或组织中的敏感设计和配置信息。

### How To Test

使用搜索引擎查找潜在的敏感信息，包括但不限于以下内容：
- 网络图表和配置 network diagrams and configurations;
- 管理员或关键人员的文档和邮件 archived posts and emails by administrators and other key staff;
- 登录过程和用户名格式 log on procedures and username formats;
- 用户名、密码、私钥 usernames, passwords, and private keys;
- 第三方、云服务配置文件 third-party, or cloud service configuration files;
- 错误消息内容 revealing error message content; and
- 开发、测试、用户接受测试和阶段版本信息 development, test, user acceptance testing (UAT), and staging versions of the website.

### 可用的搜索引擎

不同的搜素引擎有不同的结果。需要综合使用。

不限于以下种种：
- Baidu.com, China's most popular search engine.
- Bing.com, a search engine owned and operated by Microsoft, and the second most popular worldwide. Supports advanced search keywords.
- binsearch.info, a search engine for binary Usenet newsgroups.
- DuckDuckGo.com, a privacy-focused search engine that compiles results from many different sources. Supports search syntax.
- Google.com, which offers the world's most popular search engine, and uses a ranking system to attempt to return the most relevant results. Supports search operators.
- Startpage.com, a search engine that uses Google's results without collecting personal information through trackers and logs. Supports search operators.
- Shodan.com, a service for searching Internet-connected devices and services. Usage options include a limited free plan as well as paid subscription plans.

Both DuckDuckGo and Startpage offer some increased privacy to users by not utilizing trackers or keeping logs. This can provide reduced information leakage about the tester.

### 搜索选项

搜索引擎中常见的搜素选项如下:

- site:
- inurl:
- intitle:
- intext:
- filetype:

### 查看搜索引擎之前缓存的内容

可以使用```cache:```选项，查看已变更网页之前的某个历史阶段的内容。

### Google Hacking, or Dorking

这部分内容很多，可以参考[Google hacking database](https://www.exploit-db.com/google-hacking-database)，其中包括以下方面的搜索方法：

- 足迹 Footholds
- 文件包含用户名 Files containing usernames
- 敏感目录 Sensitive Directories
- Web服务检查 Web Server Detection
- 脆弱的文件 Vulnerable Files
- 脆弱的服务器 Vulnerable Servers
- 错误消息 Error Messages
- 文件包含敏感信息 Files containing juicy info
- 文件包含密码 Files containing passwords
- 敏感的在线买卖信息 Sensitive Online Shopping Info


还有个不错的选择是[Google Hacking Diggity Project](https://resources.bishopfox.com/resources/tools/google-hacking-diggity/)，这个项目对搜索引擎利用做了集成和升级。

### 补救措施 Remediation

在发布信息之前，仔细考虑设计和配置中信息的敏感性。

周期性的复查已有设计和配置信息中的敏感信息是否被发布。

## Web服务器指纹采集 Fingerprint Web Server 

ID: WSTG-INFO-002

Web服务器的指纹信息是当前运行的 web server 的类型和版本。很多自动测试工具都可以发现web server 指纹，研究者理解工具识别 web server 指纹的原理是很重要的。

### Test Objectives

确定运行的 Web server 的类型和版本，为之后发现已知漏洞做准备。

### How To Test

用于获取应用服务器指纹的技术包括：
- 标志抓取 banner grabbing
- 异常格式请求的响应诱发  eliciting responses to malformed requests
- 自动扫描工具，例如zap， nmap

#### Banner Grabbing

For example, here is the response to a request from an Apache server.
```
HTTP/1.1 200 OK
Date: Thu, 05 Sep 2019 17:42:39 GMT
Server: Apache/2.4.41 (Unix)
Last-Modified: Thu, 05 Sep 2019 17:40:42 GMT
ETag: "75-591d1d21b6167"
Accept-Ranges: bytes
Content-Length: 117
Connection: close
Content-Type: text/html
...
```

Here is another response, this time from nginx.
```
HTTP/1.1 200 OK
Server: nginx/1.17.3
Date: Thu, 05 Sep 2019 17:50:24 GMT
Content-Type: text/html
Content-Length: 117
Last-Modified: Thu, 05 Sep 2019 17:40:42 GMT
Connection: close
ETag: "5d71489a-75"
Accept-Ranges: bytes
...
```

Here's what a response from lighttpd looks like.
```
HTTP/1.0 200 OK
Content-Type: text/html
Accept-Ranges: bytes
ETag: "4192788355"
Last-Modified: Thu, 05 Sep 2019 17:40:42 GMT
Content-Length: 117
Connection: close
Date: Thu, 05 Sep 2019 17:57:57 GMT
Server: lighttpd/1.4.54

```

In these examples, the server type and version is clearly exposed. However, security-conscious applications may obfuscate their server information by modifying the header. For example, here is an excerpt from the response to a request for a site with a modified header:
```
HTTP/1.1 200 OK
Server: Website.com
Date: Thu, 05 Sep 2019 17:57:06 GMT
Content-Type: text/html; charset=utf-8
Status: 200 OK
...
```

当web server 的信息被有意模糊或抹掉，测试者可以根据响应头的fields顺序来猜测服务器类型。例如：下面的字段顺序是Apache服务器的：

```
Date
Server
Last-Modified
ETag
Accept-Ranges
Content-Length
Connection
Content-Type
```

然而，在nginx和有意模糊的服务器响应中，字段顺序可能是下列情况：
```
Server
Date
Content-Type
```
当然，这个方法也不完全可靠，需要其它方面进行佐证。

#### 发送错误形式的请求，诱发服务器进行响应

不同的服务器对异形请求有不同的响应，如果当前运行的服务器没有设置自定义的默认错误返回页，或没有完全覆盖错误异常处理，那么就有可能获得有意义的错误反馈页或信息。

例如，构造一种不存在的请求方法或协议类型，把它发给apache 服务器，得到了如下结果：
```
GET / SANTA CLAUS/1.1


HTTP/1.1 400 Bad Request
Date: Fri, 06 Sep 2019 19:21:01 GMT
Server: Apache/2.4.41 (Unix)
Content-Length: 226
Connection: close
Content-Type: text/html; charset=iso-8859-1

<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML 2.0//EN">
<html><head>
<title>400 Bad Request</title>
</head><body>
<h1>Bad Request</h1>
<p>Your browser sent a request that this server could not understand.<br />
</p>
</body></html>
```

下面的例子是发送给nginx服务器的响应：
```
GET / SANTA CLAUS/1.1


<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx/1.17.3</center>
</body>
</html>

```

下面的例子是发送给lighttpd的响应:
```
GET / SANTA CLAUS/1.1


HTTP/1.0 400 Bad Request
Content-Type: text/html
Content-Length: 345
Connection: close
Date: Sun, 08 Sep 2019 21:56:17 GMT
Server: lighttpd/1.4.54

<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
         "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
 <head>
  <title>400 Bad Request</title>
 </head>
 <body>
  <h1>400 Bad Request</h1>
 </body>
</html>
```

由上面的例子可以看出，不同web server有着不同的默认错误报告信息，根据这一点可以获得一些指纹信息。

#### Using Automated Scanning Tools

自动化扫描工具中常常有一项服务是采集webserver的指纹。

Here are some commonly-used scan tools that include web server fingerprinting functionality.
- Netcraft, an online tool that scans websites for information, including the web server.
- Nikto, an open source command line scanning tool.
- Nmap, an open source command line tool that also has a GUI, Zenmap.

### Remediation

Web server的指纹信息暴露，不能说就是一个漏洞，但这个信息容易使攻击者寻找到相关的公开漏洞以及可用的攻击载荷。所以我们建议隐藏或混淆Web server的指纹信息，较少攻击面。

补救方法有：
- 混淆服务器响应报文头信息，例如Apache's mod_headers module.
- 使用加固的反向代理服务器，来生成一个额外的中间安全层。例如：负载均衡服务器、WAF等等
- 确保 web servers 始终为最新版本，安装了最新补丁。

## 复查Web服务器元文件的信息泄露 Review Webserver Metafiles for Information Leakage

ID: WSTG-INFO-003

这部分说明了如何测试 robots.txt文件中的信息泄露，例如应用目录和文件路径。此外，防止网络爬虫或搜索引擎通过应用程序生成执行路径。

### Test Objectives

- 发现应用目录或文件夹路径的信息泄露问题
- 生成一个需要免于爬虫发现的目录列表（敏感目录）

### How To Test

- 检查 robots.txt 文件

例如，下面是google的robots.txt文件内容：
```
User-agent: *
Disallow: /search
Disallow: /sdch
Disallow: /groups
Disallow: /images
Disallow: /catalogs
...
```

上面文件中内容，提示我们google主站下，至少有 search、sdch等子路径。

robots.txt文件可以通过 Wget 或 curl 从网站根目录下获取。

```$ wget http://www.google.com/robots.txt``` 或 ```curl -O http://www.google.com/robots.txt```

Rockspider是一个自动化工具，能够生成网站的初始待爬取域，为后续爬取信息做准备。使用方法很简单：
```
$ ./rockspider.pl -www www.google.com
"Rockspider" Alpha v0.1_2

Copyright 2013 Christian Heinrich
Licensed under the Apache License, Version 2.0

1. Downloading http://www.google.com/robots.txt
2. "robots.txt" saved as "www.google.com-robots.txt"
3. Sending Allow: URIs of www.google.com to web proxy i.e. 127.0.0.1:8080
     /catalogs/about sent
     /catalogs/p? sent
     /news/directory sent
    ...
4. Done.

$
```

在分析 robots.txt文件时，可以使用 google Webmaster tools.

#### META Tag

元标记```<META>```是存放在每个HTML文档 ```HEAD``` 中的一类信息。

<meta> 元素可提供有关页面的元信息（meta-information），比如针对搜索引擎和更新频度的描述和关键词。

<meta> 标签位于文档的头部，不包含任何内容。<meta> 标签的属性定义了与文档相关联的名称/值对。

下面的一段代码限制了所有的搜索引擎建立你的网页快照。
```
<meta name="robots" content="">
<meta name="robots" content="noarchive">
```
在这里，META NAME="ROBOTS"是泛指所有的搜索引擎的，如果我们需要仅仅限制一个搜索引擎建立快照的话，就可以像如下这样去写
```<meta name="Baiduspider" content="noarchive">```

需要注意的是，这样的标记仅仅是禁止搜索引擎为你的网站建立快照.

为了让搜索引擎禁止抓取本页面，我们一般的做法是在页面的元标记中加入如下的代码：
```<META NAME="ROBOTS" CONTENT="NOINDEX,FOLLOW">```

content部分有四个命令：index、noindex、follow、nofollow，命令间以英文的“,”分隔。
- INDEX命令：告诉搜索引擎抓取这个页面
- FOLLOW命令：告诉搜索引擎可以从这个页面上找到链接，然后继续访问抓取下去。
- NOINDEX命令：告诉搜索引擎不允许抓取这个页面
- NOFOLLOW命令：告诉搜索引擎不允许从此页找到链接、拒绝其继续访问。

### Tools

- 浏览器（需要能够查看源代码）
- curl（用于下载robots.txt)
- wget
- rockspider

## 枚举Web服务器上运行的应用 Enumerate Applications on Webserver

ID：WSTG-INFO-004

测试web应用漏洞时，一个至关重要的步骤是找出有哪些特别的应用运行在服务器上。许多应用都含有已知的漏洞和已知的攻击策略，可以获得远程控制权或泄露数据。许多作为内部使用的应用没有升级或有错误配置，但却可以通过某种方式被人渗透利用。

随着虚拟web服务器的激增，传统的IP地址与web server之间的1:1关系逐渐消失。多个web站点或应用很可能公用一个IP地址，这web站点有着符号化的名字，都将解析到一个IP地址上。这种情况不仅限于托管环境（IDC机房或云服务管理），也适用于普通的公司环境。多个web应用可能对应着多个IP+端口路径，有着不同的DNS名称。

### Test Objectives

枚举存在于某个web server上的所有的web应用。

### How To Test



通常测试人员会被分派一个ip地址或域名。如果没有特别说明只测这一个地址或域名，需要通过拓扑发现或网络IP扫描确定相关的其它地址。

有3个因素影响与给定的DNS名称或IP地址相关的应用程序数量：
-  不同的URL，可以使用自动扫描工具来发现，例如burpsuite，也可以根据经验进行探索。
-  非标准端口，可以使用NMAP等工具进行扫描。例如```nmap –PN –sT –sV –p0-65535 192.168.1.100```可用来发现TCP端口服务。
-  虚拟主机（可能使用反向代理），可以通过dns查询，例如使用```host -l www.owasp.org ns1.secure.net```, ```host -t ns www.owasp.org```

### Tools

- DNS lookup tools such as nslookup, dig and similar.
- Search engines (Google, Bing and other major search engines).
- Specialized DNS-related web-based search service: see text.
- Nmap
- Nessus Vulnerability Scanner
- Nikto


## 复查网页注释和元数据的信息泄露情况 Review Webpage Comments and Metadata for Information Leakage

ID : WSTG-INFO-005

很多程序员都会在页面中加入一些注释信息和元数据信息。这些信息有可能造成信息泄露。

### Test Objectives
复查网页注释和元数据，更好的理解和发现任何信息泄露问题。

### How To Test
Web应用中的注释经常被写在HTML页面中，复查HTML源代码可以发现这些注释是否造成了信息泄露问题。

特别要注意的是：
- SQL 语句
- 用户名
- 密码
- 内部IP地址
- 调试信息等

此外，还需要检查HTML版本信息，验证版本号和数据类型定义URLS，例如:

```<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">```

其中涉及：
- strict.dtd，默认的严格的DTD
- loose.dtd，宽松DTD
- frameset.dtd，用于frameset documents的DTD

一些Meta标签不提供活动的攻击向量，但是却允许攻击者了解一个应用，例如作者：
```<META name="Author" content="Andrew Muller">```

还有一些Meta标签改变了HTTP响应头，例如 http-equiv，它把 content 属性关联到 HTTP 头部。设置了这个属性会根据属性内容修改响应头。例如：```<META http-equiv="Expires" content="Fri, 21 Dec 2012 12:34:56 GMT">```

这会导致响应头中的过期时间被改变为```Expires: Fri, 21 Dec 2012 12:34:56 GMT```。

而```<META http-equiv="Cache-Control" content="no-cache">```会导致响应头```Cache-Control: no-cache```。

如果有上面的情况，要测试是否可以使用注入攻击（例如CRLF攻击，即http数据包通过\r\n\r\n来分开http header和http body），也可以帮助判断是否存在缓存泄露数据的情况。

一个常用的Meta标签是“刷新”设置，例如：```<META http-equiv="Refresh" content="15;URL=https://www.owasp.org/index.html">```。

还有时，可以在Meta标签里指定关键词，搜索引擎可以使用这个关键词提升检索结果质量，例如：```<META name="keywords" lang="en-us" content="OWASP, security, sunshine, lollipops">```

虽然大多数web servers会使用robots文件约束正规的搜索引擎，但也可以通过Meta标签来实现，```<META name="robots" content="none">``` 就是告知搜索引擎不要检索、不要跟踪该网页和网页内的链接。

The Platform for Internet Content Selection (PICS) and Protocol for Web Description Resources (POWDER) provide infrastructure for associating meta data with Internet content.

### Tools

- Wget
- Browser “view source” function
- Eyeballs
- Curl

## 识别应用入口点 Identify Application Entry Points

ID : WSTG-INFO-006

枚举应用和它的攻击面，是在任何完整测试执行前必须要进行的，它使测试人员能够识别出可能的脆弱域。

### Test Objectives

理解如何构造请求，理解服务器给出的响应。

### How to Test

#### 黑盒测试
测试前，测试人员一定要理解应用的基本情况，知道用户和浏览器如何通信。需要走查整个应用，特别注意所有的HTTP请求（GET 和 POST 方法）。测试人员应当使用一些工具，例如OWASP-ZAP或浏览器插件，查清各种POST表单参数和URL传递参数。注意页面中的隐藏输入，可能包含了敏感信息，例如，信息状态、项目数量、价格等开发人员隐藏于页面中的信息。

经验表明，借助HTTP proxy 工具（例如BURPSUITE , ZAP)和电子表格来分析和记录这些参数是非常有价值的。代理可以追踪、拦截HTTP请求和响应，在适当的时机可以中断请求过程，并允许测试人员更换参数。

除了参数外，还必须对自定义的HTTP HEAT和BODY非常敏感。下面是一些值得分析的请求和响应。

##### HTTP REQUEST

- 找到何处使用GET方法，何处使用POST方法。
- 找到所有在POST方法中使用的参数。
- 在POST方法请求参数中，注意隐藏提交的参数。
- 找到GET方法中使用的所有参数，即URL中的查询字符串。注意分隔符可能是 &, ~, :, or 别的特定符号
- 特别注意那些能够引发攻击的参数（可能加密或编码）。
- 注意任何额外的或自定义头部，和不标准的信息，例如 debug=False.

##### HTTP RESPONSE

- 找到所有新设置的cookies
- 找到所有返回状态码为：重定向3xx、400、403 Forbidden、500 internal server errors的响应。
- 注意任何有趣的响应头部信息，例如 “Server: BIG-IP” indicates that the site is load balanced. 这可能意味着服务器有负载均衡。测试人员可能需要使用多种不同的请求参数来访问脆弱的服务器，这取决于使用负载均衡的类型。

##### 测试应用的入口

下面的例子显示了如何检查应用入口：

```
# 例1 显示了GET请求完成在线购买

GET https://x.x.x.x/shoppingApp/buyme.asp?CUSTOMERID=100&ITEM=z101a&PRICE=62.50&IP=x.x.x.x
Host: x.x.x.x
Cookie: SESSIONID=Z29vZCBqb2IgcGFkYXdhIG15IHVzZXJuYW1lIGlzIGZvbyBhbmQgcGFzc3dvcmQgaXMgYmFy

```

在这个例子中，测试人员需要注意所有的请求参数： CUSTOMERID, ITEM, PRICE, IP, and the Cookie （可能编码）

```
# 例2 显示了登录过程的POST请求

POST https://x.x.x.x/KevinNotSoGoodApp/authenticate.asp?-
service=login
Host: x.x.x.x
Cookie: SESSIONID=dGhpcyBpcyBhIGJhZCBhcHAgdGhhdCBzZXRzIHByZWRpY3RhYmxlIGNvb2tpZXMgYW5kIG1pbmUgaXMgMTIzNA==
CustomCookie=00my00trusted00ip00is00x.x.x.x00

```

POST请求消息如下:
```
user=admin&pass=pass123&debug=true&fromtrustIP=true
```

以上是黑盒测试部分。

#### 灰盒测试

通过灰盒方法对应用程序入口点进行的测试将包括上面已经标识的所有内容以及一项附加功能。如果有外部来源供应用程序从中接收数据并对其进行处理（例如SNMP traps， 系统日志消息，SMTP 或来自其他服务器的SOAP消息）。

与应用程序开发人员的会议可以确定将接受或期望用户使用的功能、输入及其格式。例如，开发人员可以帮助理解如何制定应用程序，接受的正确SOAP请求以及Web服务所驻留的位置（如果在黑盒测试过程中尚未标识Web服务或任何其他功能）。

##### OWASP 攻击面检查器 ASD

The OWASP Attack Surface Detector (ASD) 是用于静态代码分析所有可用入口点的工具。它可以集成在burpsuite-extender中或者ZAP中，还可以使用命令行工具（CLI）。

使用方法：
- 下载命令行 jar 文件：https://github.com/secdec/attack-surface-detector-cli/releases
- 运行名利如下: ```java -jar attack-surface-detector-cli-1.3.5.jar <source-code-path> [flags] ```

下面是执行```java -jar attack-surface-detector-cli-1.3.5.jar railsgoat/``` 攻击面检查的结果:
```
$ java -jar attack-surface-detector-cli-1.3.5.jar railsgoat/
Beginning endpoint detection for '<...>/railsgoat' with 1 framework types
Using framework=RAILS
[0] GET: /login (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_contro
ller.rb (lines '6'-'9')
[1] GET: /logout (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines '33'-'37')
[2] POST: /forgot_password (0 variants): PARAMETERS={email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/
password_resets_controller.rb (lines '29'-'38')
[3] GET: /password_resets (0 variants): PARAMETERS={token=name=token, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/p
assword_resets_controller.rb (lines '19'-'27')
[4] POST: /password_resets (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user=name=user, paramType=QUERY_STRING, dataType=STRING, confirm_password=name=confirm_password, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/password_resets_controller.rb (lines '5'-'17')
[5] GET: /sessions/new (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '6'-'9')
[6] POST: /sessions (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user_id=name=user_id, paramType=SESSION, dataType=STRING, remember_me=name=remember_me, paramType=QUERY_STRING, dataType=STRING, url=name=url, paramType=QUERY_STRING, dataType=STRING, email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '11'-'31')
[7] DELETE: /sessions/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines '33'-'37')
[8] GET: /users (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines '9'-'11')
[9] GET: /users/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines '13'-'15')
... snipped ...
[38] GET: /api/v1/mobile/{id} (0 variants): PARAMETERS={id=name=id, paramType=QUERY_STRING, dataType=STRING, class=name=class, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/api/v1/mobile_controller.rb (lines '8'-'13')
[39] GET: / (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '6'-'9')
Generated 40 distinct endpoints with 0 variants for a total of 40 endpoints
Successfully validated serialization for these endpoints
0 endpoints were missing code start line
0 endpoints were missing code end line
0 endpoints had the same code start and end line
Generated 36 distinct parameters
Generated 36 total parameters
- 36/36 have their data type
- 0/36 have a list of accepted values
- 36/36 have their parameter type
--- QUERY_STRING: 35
--- SESSION: 1
Finished endpoint detection for '<...>/railsgoat'
----------
-- DONE --
0 projects had duplicate endpoints
Generated 40 distinct endpoints
Generated 40 total endpoints
Generated 36 distinct parameters
Generated 36 total parameters
1/1 projects had endpoints generated
To enable logging include the -debug argument
```
如果要生成json输出文件，选哟加选项```-json```

其它用法可以参考：
- https://github.com/secdec/attack-surface-detector-zap/wiki
- https://www.portswigger.net/burp/
- https://www.telerik.com/fiddler
- https://owasp.org/www-project-attack-surface-detector/
  

### Tools
- OWASP Zed Attack Proxy (ZAP)
- Burp Suite
- Fiddler

## 画出应用的执行路线图 Map Execution Paths Through Application

ID: WSTG-INFO-007

在执行安全测试前，深入理解应用结构是非常重要的。没有完全的理解应用的布局，不大可能进行完整的测试。

### Test Objectives

绘制目标应用程序的“地图”，理解基本的工作流。

### How to test

黑盒测试中，很难测试所有的代码。不仅没有源代码，而且非常耗时。解决这个问题的一种方法是记录发现和测试了哪些代码路径。

有几种方法可以测试和衡量代码覆盖率：
- 路径：测试每一条执行路径，输入应该包括所有组合输入值、边界值。当然这个方法极有可能是非常耗时的。
- 数据流：通过外部交互（通常为用户）测试变量的分配。专注于在整个应用程序中映射数据的流，转换和使用。
- 竞赛：使用相同的数据，测试该应用的多个并发实例，比较相互差异以发现更多可能的执行路径。

#### 黑匣子测试
为了向应用程序所有者演示代码覆盖范围，测试人员可以从电子表格开始，并记录通过爬网应用程序（手动或自动）发现的所有链接。然后，测试人员可以更仔细地查看应用程序中的决策点，并调查发现了多少个重要的代码路径。然后，应将这些内容记录在电子表格中，并附上所发现路径的URL，散文和屏幕截图说明。

#### 灰盒或白盒测试
使用灰盒和白盒方法进行测试，确保为应用程序所有者提供足够的代码覆盖范围要容易得多。测试人员征求并提供给测试人员的信息将确保满足代码覆盖率的最低要求。


#### Automatic Spidering
自动搜寻器是用于自动发现特定网站上的新资源（URL）的工具。它以要访问的URL列表（称为种子）开始，该列表取决于Spider的启动方式。尽管有许多Spidering工具，但以下示例使用Zed攻击代理（ZAP）：
ZAP提供以下自动爬网功能，可以根据测试人员的需求进行选择：
- 蜘蛛站点-种子列表包含为所选站点找到的所有现有URI。
- 蜘蛛子树-种子列表包含选定节点的子树中已经找到并存在的所有现有URI。
- 蜘蛛URL-种子列表仅包含与所选节点相对应的URI（在“站点树”中）。
- 在范围内蜘蛛所有-种子列表包含用户已选择为“范围内”的所有URI。

### Tools 
- Zed Attack Proxy (ZAP)
- List of spreadsheet software ：https://en.wikipedia.org/wiki/List_of_spreadsheet_software
- Diagramming software：https://en.wikipedia.org/wiki/List_of_concept-_and_mind-mapping_software

## WEB应用框架指纹采集 Fingerprint Web Application Framework

ID: WSTG-INFO-008

web应用框架指纹信息，有利于找到相关已知的漏洞，也有决定着后续测试的过程。指纹信息包括：
- 类型
- 版本
- 配置情况
- 补丁情况
- 漏洞

### Test Objectives

为了确定目标网站使用的web框架，以便更好的选用安全测试方法。

### How to Test

#### Black Box testing

通常可以确定web框架的细节信息包括：
- HTTP headers
- Cookies
- HTML 源代码
- 专门的文件或目录

##### HTTP headers

识别web框架最基本的方法是看HTTP响应头中的```X-Powered-By```字段。

例如：
```
$ nc 127.0.0.1 80

# 结果如下：
HEAD / HTTP/1.0
HTTP/1.1 200 OK
Server: nginx/1.0.14
Date: Sat, 07 Sep 2013 08:19:15 GMT
Content-Type: text/html;charset=ISO-8859-1
Connection: close
Vary: Accept-Encoding
X-Powered-By: Mono
```
上面的例子中，所用的框架很可能是Mono。当然，这个字段的信息可能被混淆编辑过，即开发人员可能会误导攻击者。例如下面的结果，显然是被特意编辑了：

```
HTTP/1.1 200 OK
Server: nginx/1.0.14
Date: Sat, 07 Sep 2013 08:19:15 GMT
Content-Type: text/html;charset=ISO-8859-1
Connection: close
Vary: Accept-Encoding
X-Powered-By: Blood, sweat and tears
```

有时，在响应头中会有更多的字段，反映web框架信息。例如```X-Generator```字段，这需要我们仔细检查每一个HTTP头字段。
```
HTTP/1.1 200 OK
Server: nginx/1.4.1
Date: Sat, 07 Sep 2013 09:22:52 GMT
Content-Type: text/html
Connection: keep-alive
Vary: Accept-Encoding
X-Powered-By: PHP/5.4.16-1~dotdeb.1
Expires: Thu, 19 Nov 1981 08:52:00 GMT
Cache-Control: no-store, no-cache, must-revalidate, postcheck=0, pre-check=0
Pragma: no-cache
X-Generator: Swiftlet
```

##### Cookies

检查web框架特定的cookie信息，也能帮助我们确定其web框架指纹。

例如下列请求头中的cookie信息：
```
GET /cake HTTP /1.1
Host: defcon-moscow.org
User-Agent: Mozilla75.0 |Macintosh; Intel Mac OS X 10.7; rv:
22. 0) Gecko/20100101 Firefox/22 . 0
Accept: text/html, application/xhtml + xml, application/xml;
q=0.9, */*; q=0 , 8
Accept - Language: ru-ru, ru; q=0.8, en-us; q=0.5 , en; q=0 . 3
Accept - Encoding: gzip, deflate
DNT: 1
Cookie: CAKEPHP=rm72kprivgmau5fmjdesbuqi71;
Connection: Keep-alive
Cache-Control: max-age=0
```

cookie内容CAKEPHP是自动设置的，它是web框架被应用的证据。这个自动填写的cookie内容可以在cakephp的配置文件中进行修改。
```
/**
* The name of CakePHP’s session cookie.
*
* Note the guidelines for Session names states: “The session
name references
* the session id in cookies and URLs. It should contain only alphanumeric
* characters.”
* @link http://php.net/session_name
*/
Configure::write(‘Session.cookie’, ‘CAKEPHP’);
```

由于很多开发人员不会修改框架中的配置，所以使用cookie值判断web框架具有一定的可靠性。

常见的框架生成cookies值有:
|Framework|Cookie name|
|-|-|
|Zope|BITRIX_|
|CakePHP|AMP|
|Laravel|django|


##### HTML源代码

使用HTML源代码来确定当前目标应用所使用的web框架，取决于在HTML页面源代码中发现一定的模式。最常见的有以下几种：
- HTML注释，这些注释直接注明了web框架信息。
- 框架特定路径，这也是用来识别web框架指纹的方法。
- 特定的脚本变量。
- 很多框架自动生成信息保存在```<head>...</head>```之间。
- 检查整个文档，发现特殊痕迹。

常见的标记相关字符串有：
- %framework_name%
- powered by
- built upon
- running

专用标记：
|Framework|Keyword|
|-|-|
|Adobe ColdFusion|```<!-- START headerTags.cfm```|
|Microsoft ASP.NET|```__VIEWSTATE```|
|ZK|```<!-- ZK```|
|Business Catalyst|```<!-- BC_OBNW -->```|
|Indexhibit|```ndxz-studio```|

##### 专门的文件或目录

不同的框架会有不同的默认文件路径或目录安排。在渗透测试时，建议安装相应的web框架，对web框架进行深入了解。

项目fuzzdb-project/fuzzdb中记录了大量的已知框架默认路径和特征字符，可以参考使用：https://github.com/fuzzdb-project/fuzzdb

### Tools

下面是一个通用的工具列表：
- WhatWeb：http://www.morningstarsecurity.com/research/whatweb
  - 当前最好的指纹工具，安装在kali linux中
  - 使用ruby语言，可以使用字符串、正则表达式、google hack db查询、md5、url、html tag patterns、自定义ruby代码
- BlindElephant：https://community.qualys.com/community/blindelephant
  - python编写
  - 很好的静态文件检查工具，提供非常高质量的指纹信息。
- Wappalyzer：http://wappalyzer.com
  - 一个firefox、chrome插件。
  - 使用正则表达式进行匹配。

例子：
```
pentester$ python BlindElephant.py http://my_target drupal
Loaded /Library/Python/2.7/site-packages/blindelephant/
dbs/drupal.pkl with 145 versions, 478 differentiating paths,
and 434 version groups.
Starting BlindElephant fingerprint for version of drupal at
http://my_target
Hit http://my_target/CHANGELOG.txt
File produced no match. Error: Retrieved file doesn’t match
known fingerprint. 527b085a3717bd691d47713dff74acf4
Hit http://my_target/INSTALL.txt
File produced no match. Error: Retrieved file doesn’t match
known fingerprint. 14dfc133e4101be6f0ef5c64566da4a4
Hit http://my_target/misc/drupal.js
Possible versions based on result: 7.12, 7.13, 7.14
Hit http://my_target/MAINTAINERS.txt
File produced no match. Error: Retrieved file doesn’t match
known fingerprint. 36b740941a19912f3fdbfcca7caa08ca
Hit http://my_target/themes/garland/style.css
Possible versions based on result: 7.2, 7.3, 7.4, 7.5, 7.6, 7.7,
7.8, 7.9, 7.10, 7.11, 7.12, 7.13, 7.14
...
Fingerprinting resulted in:
7.14
Best Guess: 7.14
```

### 补救措施

通用防护指南：
- 确保没有直接显示的框架标志/文字 Make sure there are no visual markers disclosing the framework
- 移除任何不必要的注释 Remove any unnecessary comments (copyrights, bug information, specific framework comments)
- 移除META和生成标签 Remove META and generator tags
- 使用公司自己的css或js文件，不要使用框架专用目录 Use the companies own css or js files and do not store those in a framework-specific folders
- 不要使用默认的脚本，或者在使用前将其进行混淆处理。Do not use default scripts on the page or obfuscate them if they must be used.
- 移除不必要的或不使用的服务器端文件。文件可能暴漏服务器版本和安装信息。
- 限制对其它文件的访问，用户访问这些文件时返回404错误。有些工具可以自动完成这些工作。例如WordPress的Stealthlogin工具。
- 为了抵制通过校验和checksum来猜测，可以改变文件路径和文件内容。
- 还可以在路径中增加一些属于其它框架的文件，作为噪声路径和文件。

## Web应用指纹采集 Fingerprint Web Application

ID: WSTG-INFO-009

太阳之下没有新东西（There is nothing new under the sun)，所有你能想到的开发过程或软件功能都有人做过尝试，存在大量的开源代码。我们要测试的web应用，极有可能来自某个已知的应用，例如 wordpress，phpBB，Mediawiki，等等。

如果能够识别这些代码，将大幅减少我们的测试工作。这些已知的应用通常含有以下已知的部分：
- HTML headers
- cookies
- directory structures

### Test Objectives

识别web应用和版本，发现已知的漏洞和适当的渗透方法。

### How to Test

#### Cookies
相对可靠的识别web应用指纹的方法是检查应用专用的cookies。

例如下面这段HTTP请求：
```
GET / HTTP/1.1
User-Agent: Mozilla/5.0 (Windows NT 6.2; WOW64; rv:31.0)
Gecko/20100101 Firefox/31.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
‘’’Cookie: wp-settings-time-1=1406093286; wp-settingstime-2=1405988284’’’
DNT: 1
Connection: keep-alive
Host: blog.owasp.org
```

上面的``` wp-settings-time-1 ```是自动填入的，说明了使用的框架是wordpress。

更多的标识信息，可以参考  Common Application Identifiers .

#### HTML源代码

常用的几种寻找源代码标志的方法：
- 检查注释信息
- 专用路径
- 专用CSS,js路径或链接
- 专用脚本变量
- 专用meta元素

#### 专用文件和目录

这个主要参考 [FuzzDB wordlists of predictable files/folders.](https://github.com/fuzzdb-project/fuzzdb)

### Tools

下面是一些已知可用的工具，可用于识别应用指纹：
- WhatWeb
- Wappalyzer
- BlindElephant

### Remediation

同上一测试内容。

## 画出应用架构图 Map Application Architecture 

ID : WSTG-INFO-010

互连的异构Web服务器上可能有数百个Web应用程序，而Web应用程序配置管理和审查是安全测试的必有环节。为了能够覆盖所有的配置型安全问题，在审查前有必要将网络和应用程序的体系结构画图，确定其基本构成及相互关系。

### How to Test

#### 应用架构画图

需要执行一些测试来判断Web应用程序中存在哪些组件。

在小型部署中，可能会由一个web server，该server执行c、perl、python、shell CGIs应用程序，还可能包括访问控制机制。

在复杂的部署中，例如在线银行系统，可能涉及多个服务器：反向代理服务器、前端Web服务器、应用服务器、数据库服务器、LDAP服务器等等。这些服务器每个都有不同的用途和功能，可能部署在不同的网络区域中，其间可能有防火墙等安全设备，以及不同的访问控制方式。

如果能从开发团队中获取相关文档，当然是非常好的；但很多渗透测试中，甲方并不提供完整文档，所以想完整画出应用架构图是非常困难的。

如果没有文档支持，测试人员应当：
- 先假设应用为简单部署（单服务器）；
- 获取其它测试信息进行综合分析，判断可能的架构
- 通过扫描结果判断有没有防火墙
- 通过分析web服务器的标识信息（banner）、比较当前响应结果与预期结果等来判断是否存在反向代理服务器，例如由“WebSEAL”。
  - 反向代理可能是WAF、IDS、Load balance、缓存等...
- 进行压力测试，查看是否存在负载均衡策略（一个域名可能后台映射为多个IP端口）
- 检查日期、时间、 Date header等


